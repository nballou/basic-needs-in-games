[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "",
    "text": "Show code (Load required R packages)\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(glmmTMB)\nlibrary(lme4)\nlibrary(marginaleffects)\nlibrary(mice)\nlibrary(howManyImputations)\nlibrary(future)\nlibrary(modelsummary)\nlibrary(lubridate)\nlibrary(DHARMa)\nlibrary(brms)\nlibrary(broom.mixed)\nlibrary(psych)\nlibrary(tinytable)\nlibrary(litedown)\nlibrary(patchwork)\nlibrary(ggridges)\nlibrary(ggdist)\nlibrary(splines)\nlibrary(scales)\nlibrary(janitor)\nShow code (Set random seed and global options)\nset.seed(8675309)\noptions(scipen = 999, timeout = 600)\n\ntheme_set(theme_minimal())\ntheme_update(\n  plot.background = element_rect(fill = \"white\", color = NA),\n  panel.background = element_rect(fill = \"white\", color = NA),\n  strip.background = element_rect(fill = \"black\"),\n  strip.text = element_text(color = \"white\", size = 10),\n  axis.text.y = element_text(color = \"black\", size = 10),\n  axis.text.x = element_text(color = \"black\", size = 10),\n  panel.grid.minor = element_blank(),\n  panel.border = element_rect(\n    colour = \"black\",\n    fill = NA,\n    linewidth = 1\n  )\n)\n\n# Define consistent color palette for all visualizations\ncolors &lt;- list(\n  game_ns = \"#4477AA\", # Blue for game need satisfaction\n  global_ns = \"#66CCEE\", # Cyan for global need satisfaction\n  global_nf = \"#EE6677\", # Red for global need frustration\n  nintendo = \"#E60012\", # Nintendo red\n  xbox = \"#107C10\", # Xbox green\n  steam = \"#171A21\", # Steam dark\n  within = \"#228833\", # Green for within-person variance\n  between = \"#BBBBBB\" # Gray for between-person variance\n)\n\n# Define human-readable labels for snake_case column names\nlabels &lt;- c(\n  # Base variables\n  \"game_ns\" = \"Game need satisfaction\",\n  \"game_nf\" = \"Game need frustration\",\n  \"global_ns\" = \"Global need satisfaction\",\n  \"global_nf\" = \"Global need frustration\",\n  \"session_length\" = \"Session length\",\n  \"session_gap\" = \"Time to next session\",\n  # Within-person\n  \"game_ns_cw\" = \"Game need satisfaction (within)\",\n  \"game_nf_cw\" = \"Game need frustration (within)\",\n  \"global_ns_cw\" = \"Global need satisfaction (within)\",\n  \"global_nf_cw\" = \"Global need frustration (within)\",\n  # Between-person\n  \"game_ns_cb\" = \"Game need satisfaction (between)\",\n  \"game_nf_cb\" = \"Game need frustration (between)\",\n  \"global_ns_cb\" = \"Global need satisfaction (between)\",\n  \"global_nf_cb\" = \"Global need frustration (between)\",\n  # Within-person (alternate)\n  \"game_ns (within-person)\" = \"Game need satisfaction (within-person)\",\n  \"global_ns (within-person)\" = \"Global need satisfaction (within-person)\",\n  \"global_nf (within-person)\" = \"Global need frustration (within-person)\",\n  # Between-person (alternate)\n  \"game_ns (between-person)\" = \"Game need satisfaction (between-person)\",\n  \"global_ns (between-person)\" = \"Global need satisfaction (between-person)\",\n  \"global_nf (between-person)\" = \"Global need frustration (between-person)\",\n  # Interaction\n  \"game_ns_cw:global_nf_cw\" = \"Game need satisfaction × Global need frustration (within)\",\n  # Displacement\n  \"displaced_core_domain\" = \"Displaced core domain\",\n  \"displaced_core_domainTRUE\" = \"Displaced core domain\",\n  # Variance components\n  \"Within-person\" = \"Within-person\",\n  \"Between-person\" = \"Between-person\",\n  # Other\n  \"(Intercept)\" = \"Intercept\"\n)\n\n# Load custom plotting functions\nsource(\"R/plot_marginal_effects.R\")\nsource(\"R/helpers.R\")\nShow code (Download and load raw data from Zenodo)\n# Download data from Zenodo (one-time download, then cached locally)\nzenodo_url &lt;- \"https://zenodo.org/records/17609160/files/digital-wellbeing/open-play-v1.0.0.zip?download=1\"\nzip_path &lt;- \"data/open-play-v1.0.0.zip\"\n\nif (!file.exists(zip_path)) {\n  dir.create(dirname(zip_path), showWarnings = FALSE, recursive = TRUE)\n\n  # Set longer timeout for large file (194MB) - default is 60 seconds\n  options(timeout = max(600, getOption(\"timeout\")))\n\n  message(\"Downloading 194MB file from Zenodo (may take a few minutes)...\")\n  tryCatch(\n    {\n      download.file(zenodo_url, zip_path, mode = \"wb\", method = \"libcurl\")\n      message(\"Download complete!\")\n    },\n    error = function(e) {\n      message(\"Download failed. Please download manually from:\")\n      message(zenodo_url)\n      message(glue(\"And save to: {normalizePath(zip_path, mustWork = FALSE)}\"))\n      stop(e)\n    }\n  )\n}\n\n# Extract zip if not already extracted\nextract_dir &lt;- \"data/open-play-v1.0.0\"\nif (!dir.exists(extract_dir)) {\n  message(\"Extracting zip archive...\")\n  unzip(zip_path, exdir = \"data\")\n  # Rename the extracted folder to a simpler name\n  extracted_folder &lt;- list.dirs(\"data\", recursive = FALSE, full.names = TRUE)\n  extracted_folder &lt;- extracted_folder[grepl(\n    \"digital-wellbeing-open-play\",\n    extracted_folder\n  )]\n  if (length(extracted_folder) == 1 && extracted_folder != extract_dir) {\n    file.rename(extracted_folder, extract_dir)\n  }\n}\n\n# Read files from extracted directory\nintake &lt;- read_csv(\n  file.path(extract_dir, \"data/clean/survey_intake.csv.gz\"),\n  guess_max = 10000\n)\nsurveys &lt;- read_csv(file.path(\n  extract_dir,\n  \"data/clean/survey_daily.csv.gz\"\n)) |&gt;\n  filter(pid %in% intake$pid)\nxbox &lt;- read_csv(file.path(extract_dir, \"data/clean/xbox.csv.gz\"))\nnintendo &lt;- read_csv(file.path(extract_dir, \"data/clean/nintendo.csv.gz\"))\nsteam &lt;- read_csv(\n  file.path(extract_dir, \"data/clean/steam.csv.gz\"),\n  guess_max = 10000\n)\n\n# Load helper functions\nsource(file.path(extract_dir, \"R/helpers.R\"))\nShow code (Process telemetry into hourly playtime with timezone adjustments)\n# merge with the local time zone offsets from intake\n# Note: We keep country and local_timezone for DST-aware conversion\ntz_map &lt;- intake |&gt;\n  mutate(\n    pid = as.character(pid),\n    country,\n    local_timezone,\n    .keep = \"none\"\n  ) |&gt;\n  distinct(pid, .keep_all = TRUE)\n\n# aggregate data at each level of granularity (session, hourly, daily)\n# --- 1) SESSION-LEVEL (Nintendo + Xbox) ------------------------------------\nsessions_telemetry &lt;- bind_rows(\n  xbox |&gt; mutate(platform = \"Xbox\"),\n  nintendo |&gt; mutate(platform = \"Nintendo\")\n) |&gt;\n  left_join(tz_map, by = \"pid\") |&gt;\n  filter(!is.na(local_timezone)) |&gt;\n  mutate(\n    # Calculate DST-aware offset for each timestamp\n    offset_start = get_dst_offset(session_start, country, local_timezone),\n    offset_end = get_dst_offset(session_end, country, local_timezone),\n    # Add offset to get local time values (keeping UTC label for compatibility)\n    start_local = session_start + offset_start,\n    end_local = session_end + offset_end,\n    duration_min = as.numeric(difftime(\n      session_end,\n      session_start,\n      units = \"mins\"\n    ))\n  ) |&gt;\n  filter(\n    !is.na(session_start),\n    !is.na(session_end),\n    session_end &gt; session_start,\n    duration_min &gt;= 1\n  )\n\n# --- 2) HOURLY (Nintendo + Xbox expanded) ----------------------------------\n# expand sessions into local-hour bins, compute overlap minutes, and add UTC hour\nhourly_from_sessions &lt;- sessions_telemetry |&gt;\n  filter(!is.na(start_local), !is.na(end_local)) |&gt;\n  mutate(\n    h0_local = floor_date(start_local, \"hour\"),\n    h1_local = floor_date(end_local - seconds(1), \"hour\"),\n    n_hours = as.integer(difftime(h1_local, h0_local, units = \"hours\")) + 1\n  ) |&gt;\n  filter(!is.na(n_hours), n_hours &gt; 0) |&gt;\n  tidyr::uncount(n_hours, .remove = FALSE, .id = \"k\") |&gt;\n  mutate(\n    hour_start_local = h0_local + hours(k - 1),\n    minutes = pmax(\n      0,\n      as.numeric(difftime(\n        pmin(end_local, hour_start_local + hours(1)),\n        pmax(start_local, hour_start_local),\n        units = \"mins\"\n      ))\n    ),\n    # Convert back to UTC (this preserves the instant, just changes label)\n    hour_start_utc = with_tz(hour_start_local, tzone = \"UTC\")\n  ) |&gt;\n  select(pid, platform, title_id, hour_start_local, hour_start_utc, minutes) |&gt;\n  group_by(pid, platform, title_id, hour_start_local, hour_start_utc) |&gt;\n  summarise(minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\nhourly_from_steam &lt;- steam |&gt;\n  select(pid, title_id, datetime_hour_start, minutes) |&gt;\n  mutate(pid = as.character(pid)) |&gt;\n  left_join(tz_map, by = \"pid\") |&gt;\n  filter(!is.na(local_timezone)) |&gt;\n  mutate(\n    platform = \"Steam\",\n    hour_start_utc = datetime_hour_start,\n    offset = get_dst_offset(datetime_hour_start, country, local_timezone),\n    # Note: These are local time values with UTC labels due to R's POSIXct limitation\n    hour_start_local = datetime_hour_start + offset\n  ) |&gt;\n  select(pid, platform, title_id, hour_start_local, hour_start_utc, minutes) |&gt;\n  group_by(pid, platform, title_id, hour_start_local, hour_start_utc) |&gt;\n  summarise(minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\nhourly_telemetry &lt;- bind_rows(hourly_from_sessions, hourly_from_steam)\n\n# --- 3) DAILY (Nintendo + Xbox + Steam; collapse hourly to days) -----------\ndaily_telemetry &lt;- hourly_telemetry |&gt;\n  mutate(\n    day_local = as.Date(hour_start_local),\n  ) |&gt;\n  group_by(pid, platform, day_local) |&gt;\n  summarise(minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\n# --- 4) weekly\nweekly_telemetry &lt;- daily_telemetry |&gt;\n  mutate(\n    week = floor_date(day_local, \"week\")\n  ) |&gt;\n  group_by(pid, platform, week) |&gt;\n  summarise(minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\")\n\ntelemetry_spans &lt;- daily_telemetry |&gt;\n  group_by(pid, platform) |&gt;\n  summarise(\n    telemetry_start = min(day_local, na.rm = TRUE),\n    telemetry_end = max(day_local, na.rm = TRUE) + hours(1), # end of last hour bin\n    week = floor_date(telemetry_end, \"week\"),\n    n_weeks = as.integer(difftime(\n      telemetry_end,\n      telemetry_start,\n      units = \"weeks\"\n    )) +\n      1,\n    .groups = \"drop\"\n  )\nShow code (Prepare survey data and calculate play windows)\n# Step 1: Prepare data for imputation\n# Note: We only impute individual items, not composites (to avoid collinearity)\n# Composites will be calculated post-imputation\nsurveys &lt;- surveys |&gt;\n  filter(!bpnsfs_failed_att_check) |&gt;\n  mutate(wave = as.factor(wave))\n\n# Calculate play windows (both 24h and 12h for sensitivity analyses)\nplay_24h &lt;- surveys |&gt;\n  mutate(\n    survey_time = as.POSIXct(date, tz = \"UTC\"),\n    window_end = survey_time + hours(24)\n  ) |&gt;\n  left_join(\n    hourly_telemetry |&gt; select(pid, hour_start_utc, minutes),\n    by = join_by(\n      pid,\n      y$hour_start_utc &gt;= x$survey_time,\n      y$hour_start_utc &lt; x$window_end\n    )\n  ) |&gt;\n  summarise(\n    play_minutes_24h = sum(minutes, na.rm = TRUE),\n    .by = c(pid, survey_time)\n  )\n\nplay_12h &lt;- surveys |&gt;\n  mutate(\n    survey_time = as.POSIXct(date, tz = \"UTC\"),\n    window_end = survey_time + hours(12)\n  ) |&gt;\n  left_join(\n    hourly_telemetry |&gt; select(pid, hour_start_utc, minutes),\n    by = join_by(\n      pid,\n      y$hour_start_utc &gt;= x$survey_time,\n      y$hour_start_utc &lt; x$window_end\n    )\n  ) |&gt;\n  summarise(\n    play_minutes_12h = sum(minutes, na.rm = TRUE),\n    .by = c(pid, survey_time)\n  )\n\nplay_6h &lt;- surveys |&gt;\n  mutate(\n    survey_time = as.POSIXct(date, tz = \"UTC\"),\n    window_end = survey_time + hours(6)\n  ) |&gt;\n  left_join(\n    hourly_telemetry |&gt; select(pid, hour_start_utc, minutes),\n    by = join_by(\n      pid,\n      y$hour_start_utc &gt;= x$survey_time,\n      y$hour_start_utc &lt; x$window_end\n    )\n  ) |&gt;\n  summarise(\n    play_minutes_6h = sum(minutes, na.rm = TRUE),\n    .by = c(pid, survey_time)\n  )\n\nplay_24h_pre &lt;- surveys |&gt;\n  mutate(\n    survey_time = as.POSIXct(date, tz = \"UTC\"),\n    window_start = survey_time - hours(24)\n  ) |&gt;\n  left_join(\n    hourly_telemetry |&gt; select(pid, hour_start_utc, minutes),\n    by = join_by(\n      pid,\n      y$hour_start_utc &gt;= x$window_start,\n      y$hour_start_utc &lt; x$survey_time\n    )\n  ) |&gt;\n  summarise(\n    play_minutes_24h_pre = sum(minutes, na.rm = TRUE),\n    .by = c(pid, survey_time)\n  )\n\n# Prepare intake auxiliary variables\nintake_aux &lt;- intake |&gt;\n  mutate(\n    gender = ifelse(gender %in% c(\"Man\", \"Woman\"), gender, \"Non-binary/other\"),\n    # Extract numeric values from WEMWBS response strings\n    across(wemwbs_1:wemwbs_7, ~ as.numeric(str_extract(.x, \"^\\\\d+\"))),\n    wemwbs = rowMeans(pick(wemwbs_1:wemwbs_7), na.rm = TRUE)\n  ) |&gt;\n  select(\n    pid,\n    age,\n    gender,\n    edu_level,\n    employment,\n    marital_status,\n    life_sat_baseline = life_sat,\n    wemwbs,\n    diaries_completed,\n    self_reported_weekly_play\n  )\n\n# Load pre-classified activity categories\nactivity_categories &lt;- read_csv(\"data/activity_categories.csv\") |&gt;\n  mutate(wave = as.factor(wave))\n\nsurveys &lt;- surveys |&gt;\n  mutate(survey_time = as.POSIXct(date, tz = \"UTC\")) |&gt;\n  left_join(play_24h, by = c(\"pid\", \"survey_time\")) |&gt;\n  left_join(play_12h, by = c(\"pid\", \"survey_time\")) |&gt;\n  left_join(play_6h, by = c(\"pid\", \"survey_time\")) |&gt;\n  left_join(play_24h_pre, by = c(\"pid\", \"survey_time\")) |&gt;\n  left_join(intake_aux, by = \"pid\") |&gt;\n  left_join(activity_categories, by = c(\"pid\", \"wave\")) |&gt;\n  mutate(\n    # Rename self-reported play to distinguish from telemetry\n    self_reported_played_24h = played24hr,\n    # Telemetry-based play (post-survey windows)\n    telemetry_played_any_24h = play_minutes_24h &gt; 0,\n    telemetry_played_any_12h = play_minutes_12h &gt; 0,\n    telemetry_played_any_6h = play_minutes_6h &gt; 0,\n    # Telemetry-based play (pre-survey window)\n    telemetry_played_any_24h_pre = play_minutes_24h_pre &gt; 0\n  ) |&gt;\n  select(\n    pid,\n    wave,\n    # Auxiliary predictors (not imputed)\n    date,\n    age,\n    gender,\n    edu_level,\n    employment,\n    marital_status,\n    life_sat_baseline,\n    wemwbs,\n    diaries_completed,\n    self_reported_weekly_play,\n    # Self-reported play (used to control BANGS imputation)\n    self_reported_played_24h,\n    # Variables to impute: individual items only (composites calculated post-imputation)\n    bpnsfs_1,\n    bpnsfs_2,\n    bpnsfs_3,\n    bpnsfs_4,\n    bpnsfs_5,\n    bpnsfs_6,\n    bangs_1,\n    bangs_2,\n    bangs_3,\n    bangs_4,\n    bangs_5,\n    bangs_6,\n    displaced_core_domain,\n    # Telemetry (not imputed in mice, but needed for analysis)\n    telemetry_played_any_24h,\n    play_minutes_24h,\n    telemetry_played_any_12h,\n    play_minutes_12h,\n    telemetry_played_any_6h,\n    play_minutes_6h,\n    telemetry_played_any_24h_pre,\n    play_minutes_24h_pre\n  )\nShow code (Run MICE imputation on analytical sample)\n# Step 2: Multiple imputation in wide format\n#\n# Main analysis uses analytical sample only (≥15 waves, N~555)\n# - Higher quality data → stable FMI estimates\n# - Run determine_m_imputations.qmd to calculate required M\n# - Update M_IMPUTATIONS to recommended value\n#\n# Sensitivity analysis (full sample imputation) in separate chunk below\n\n# Define minimum waves threshold for analytical sample\nmin_waves &lt;- 15\nfull_eligible_pids &lt;- unique(surveys$pid)\n\nmessage(glue(\n  \"Imputing analytical sample: {length(unique(surveys$pid[surveys$diaries_completed &gt;= min_waves]))}/{length(full_eligible_pids)} participants with ≥{min_waves} waves\"\n))\n\n# Separate telemetry (no missing data) from survey variables (to be imputed)\n# Filter to analytical sample here without overwriting surveys\ntelemetry_vars &lt;- surveys |&gt;\n  filter(diaries_completed &gt;= min_waves) |&gt;\n  select(\n    pid,\n    wave,\n    date,\n    telemetry_played_any_24h,\n    play_minutes_24h,\n    telemetry_played_any_12h,\n    play_minutes_12h,\n    telemetry_played_any_6h,\n    play_minutes_6h,\n    telemetry_played_any_24h_pre,\n    play_minutes_24h_pre\n  )\n\n# Convert to wide format for imputation\n# Auxiliary variables go in id_cols (used as predictors, not imputed)\n# Only impute individual items, not composite scores (to avoid collinearity)\nsurveys_wide &lt;- surveys |&gt;\n  filter(diaries_completed &gt;= min_waves) |&gt;\n  select(\n    pid,\n    wave,\n    age,\n    gender,\n    edu_level,\n    employment,\n    marital_status,\n    life_sat_baseline,\n    wemwbs,\n    diaries_completed,\n    self_reported_weekly_play,\n    self_reported_played_24h,\n    displaced_core_domain,\n    bpnsfs_1,\n    bpnsfs_2,\n    bpnsfs_3,\n    bpnsfs_4,\n    bpnsfs_5,\n    bpnsfs_6,\n    bangs_1,\n    bangs_2,\n    bangs_3,\n    bangs_4,\n    bangs_5,\n    bangs_6\n  ) |&gt;\n  pivot_wider(\n    id_cols = c(\n      pid,\n      age,\n      gender,\n      edu_level,\n      employment,\n      marital_status,\n      life_sat_baseline,\n      wemwbs,\n      diaries_completed,\n      self_reported_weekly_play\n    ),\n    names_from = wave,\n    values_from = c(\n      self_reported_played_24h,\n      displaced_core_domain,\n      bpnsfs_1,\n      bpnsfs_2,\n      bpnsfs_3,\n      bpnsfs_4,\n      bpnsfs_5,\n      bpnsfs_6,\n      bangs_1,\n      bangs_2,\n      bangs_3,\n      bangs_4,\n      bangs_5,\n      bangs_6\n    ),\n    names_sep = \"_w\"\n  )\n\n# Set up imputation model\nM_IMPUTATIONS &lt;- 27\n\n# Set up imputation methods\n# Self-reported play: use logistic regression (binary Yes/No)\nplayed_vars &lt;- names(surveys_wide)[grepl(\n  \"^self_reported_played_24h_w\",\n  names(surveys_wide)\n)]\n# BPNSFS items: always impute when missing (global need satisfaction)\nbpnsfs_vars &lt;- names(surveys_wide)[grepl(\n  \"^bpnsfs_[1-6]_w\",\n  names(surveys_wide)\n)]\n# BANGS items: only impute conditionally (see where matrix below)\nbangs_vars &lt;- names(surveys_wide)[grepl(\"^bangs_[1-6]_w\", names(surveys_wide))]\n# Displaced core domain: always impute when missing\ndisplaced_vars &lt;- names(surveys_wide)[grepl(\n  \"^displaced_core_domain_w\",\n  names(surveys_wide)\n)]\n\nmethods &lt;- setNames(rep(\"\", ncol(surveys_wide)), names(surveys_wide))\nmethods[played_vars] &lt;- \"logreg\" # Binary outcome\nmethods[c(bpnsfs_vars, bangs_vars, displaced_vars)] &lt;- \"pmm\"\n\n# Explicitly exclude person-level variables from imputation\n# These either have no within-person variance or are complete\nperson_level_vars &lt;- c(\n  \"pid\",\n  \"age\",\n  \"gender\",\n  \"edu_level\",\n  \"employment\",\n  \"marital_status\",\n  \"life_sat_baseline\",\n  \"wemwbs\",\n  \"diaries_completed\",\n  \"self_reported_weekly_play\"\n)\nmethods[person_level_vars] &lt;- \"\"\n\n# Create WHERE matrix for conditional imputation\n# Default: impute all missing cells\nwhere_matrix &lt;- is.na(surveys_wide)\n\n# For BANGS items: only impute when person reported playing (or play status unknown)\n# Do NOT impute when self_reported_played_24h == \"No\"\nfor (bangs_var in bangs_vars) {\n  wave_num &lt;- str_extract(bangs_var, \"\\\\d+$\")\n  played_var &lt;- paste0(\"self_reported_played_24h_w\", wave_num)\n\n  if (played_var %in% names(surveys_wide)) {\n    # Set to FALSE (don't impute) where played==\"No\" AND bangs is missing\n    no_play &lt;- surveys_wide[[played_var]] == \"No\" &\n      is.na(surveys_wide[[bangs_var]])\n    where_matrix[no_play, bangs_var] &lt;- FALSE\n  }\n}\n\nmessage(glue(\"Conditional imputation setup:\"))\nmessage(glue(\"  BANGS items: only impute when played=Yes or played=NA\"))\nmessage(glue(\"  BPNSFS items: always impute\"))\nmessage(glue(\"  Self-reported play: impute when missing\"))\n\n# SPEED OPTIMIZATION: Use quickpred() to create sparse predictor matrix\npred &lt;- quickpred(\n  surveys_wide,\n  mincor = 0.3,\n  minpuc = 0.3,\n  include = c(\n    \"age\",\n    \"wemwbs\",\n    \"self_reported_weekly_play\"\n  ),\n  exclude = c(\n    \"pid\",\n    \"gender\",\n    \"edu_level\",\n    \"employment\",\n    \"marital_status\",\n    \"diaries_completed\"\n  )\n)\n\n# DIAGNOSTIC: Check for collinearity issues in analytical sample\nmessage(glue(\"\\n=== COLLINEARITY DIAGNOSTICS ===\"))\n\n# Check for variables with zero variance\nzero_var &lt;- sapply(surveys_wide, function(x) {\n  if (is.numeric(x)) {\n    v &lt;- var(x, na.rm = TRUE)\n    !is.na(v) && v &lt; 1e-10\n  } else {\n    FALSE\n  }\n})\n\nif (any(zero_var, na.rm = TRUE)) {\n  message(glue(\n    \"⚠️  Variables with zero variance: {paste(names(which(zero_var)), collapse=', ')}\"\n  ))\n}\n\n# Check for perfect/near-perfect correlations among items to be imputed\nitems_to_check &lt;- c(\n  grep(\"^bpnsfs_[1-6]_w\", names(surveys_wide), value = TRUE),\n  grep(\"^bangs_[1-6]_w\", names(surveys_wide), value = TRUE)\n)\n\nif (length(items_to_check) &gt; 1) {\n  cor_mat &lt;- cor(surveys_wide[, items_to_check], use = \"pairwise.complete.obs\")\n  diag(cor_mat) &lt;- 0 # Ignore diagonal\n\n  high_cor &lt;- which(abs(cor_mat) &gt; 0.9999, arr.ind = TRUE)\n\n  if (nrow(high_cor) &gt; 0) {\n    message(glue(\"⚠️  PERFECT CORRELATIONS DETECTED:\"))\n    for (i in 1:min(nrow(high_cor), 10)) {\n      # Show first 10\n      var1 &lt;- items_to_check[high_cor[i, 1]]\n      var2 &lt;- items_to_check[high_cor[i, 2]]\n      r &lt;- cor_mat[high_cor[i, 1], high_cor[i, 2]]\n      message(glue(\"  {var1} &lt;-&gt; {var2}: r = {round(r, 6)}\"))\n    }\n  } else {\n    message(glue(\n      \"✓ No perfect correlations detected (max r = {round(max(abs(cor_mat), na.rm=TRUE), 3)})\"\n    ))\n  }\n}\n\n# Report predictor matrix density\npred_density &lt;- 100 * mean(pred != 0)\nmessage(glue(\"Predictor matrix density: {round(pred_density, 1)}%\"))\n\n# Check where matrix for potential issues\nn_cells_to_impute &lt;- sum(where_matrix)\nn_total_cells &lt;- prod(dim(where_matrix))\npct_to_impute &lt;- 100 * n_cells_to_impute / n_total_cells\nmessage(glue(\n  \"Cells to impute: {n_cells_to_impute}/{n_total_cells} ({round(pct_to_impute, 1)}%)\"\n))\n\n# Check for variables with extreme missingness\nvars_to_impute &lt;- names(surveys_wide)[methods != \"\"]\nmiss_pct &lt;- sapply(surveys_wide[vars_to_impute], function(x) {\n  100 * mean(is.na(x))\n})\nhigh_miss &lt;- miss_pct &gt; 80\n\nif (any(high_miss)) {\n  message(glue(\"⚠️  Variables with &gt;80% missing:\"))\n  for (v in names(which(high_miss))) {\n    message(glue(\"  {v}: {round(miss_pct[v], 1)}%\"))\n  }\n}\n\nmessage(glue(\"=== END DIAGNOSTICS ===\\n\"))\n\n# Check if imputation already exists\nimp_file &lt;- \"data/imputation_analytical.csv.gz\"\n\nif (file.exists(imp_file)) {\n  message(glue(\"Loading existing imputation from {imp_file}\"))\n  imp_long &lt;- read_csv(imp_file, show_col_types = FALSE)\n\n  # Convert back to mids object\n  imp &lt;- as.mids(imp_long)\n  message(glue(\"Loaded imputation object (M={imp$m})\"))\n} else {\n  message(glue(\"No existing imputation found - running MICE\"))\n\n  message(glue(\n    \"Running MICE: M={M_IMPUTATIONS}, N={nrow(surveys_wide)}, started {Sys.time()}\"\n  ))\n\n  imp &lt;- futuremice(\n    data = surveys_wide,\n    m = M_IMPUTATIONS,\n    method = methods,\n    predictorMatrix = pred,\n    where = where_matrix,\n    maxit = 5,\n    n.core = parallel::detectCores() - 1,\n    parallelseed = 8675309\n  )\n\n  message(glue(\"Completed {Sys.time()}\"))\n\n  # Save imputation results as compressed CSV\n  imp_long &lt;- complete(imp, action = \"long\", include = TRUE)\n  write_csv(imp_long, imp_file)\n  message(glue(\"Saved imputation to {imp_file}\"))\n\n  # Diagnostic checks (only after fresh imputation)\n  if (nrow(imp$loggedEvents) &gt; 0) {\n    message(glue(\n      \"Warning: {nrow(imp$loggedEvents)} logged events during imputation\"\n    ))\n    print(head(imp$loggedEvents))\n  } else {\n    message(\"No logged events - imputation completed without issues\")\n  }\n}\nShow code (Calculate composites and within/between-person centering)\n# Post-imputation centering\nm_imputations &lt;- M_IMPUTATIONS\n\nmessage(glue(\"=== Post-imputation processing (M={m_imputations}) ===\"))\n\n# Convert to long format and calculate composite scores from imputed items\ndaily_imputed &lt;- complete(imp, action = \"long\", include = TRUE) |&gt;\n  pivot_longer(\n    cols = -c(\n      .imp,\n      .id,\n      pid,\n      age,\n      gender,\n      edu_level,\n      employment,\n      marital_status,\n      life_sat_baseline,\n      wemwbs,\n      diaries_completed,\n      self_reported_weekly_play\n    ),\n    names_to = c(\".value\", \"wave\"),\n    names_pattern = \"(.+)_w(.+)\"\n  ) |&gt;\n  mutate(wave = as.factor(wave)) |&gt;\n  # Calculate composite scores from imputed individual items\n  mutate(\n    global_ns = rowMeans(pick(bpnsfs_1, bpnsfs_3, bpnsfs_5), na.rm = TRUE),\n    global_nf = rowMeans(pick(bpnsfs_2, bpnsfs_4, bpnsfs_6), na.rm = TRUE),\n    game_ns = rowMeans(pick(bangs_1, bangs_3, bangs_5), na.rm = TRUE),\n    game_nf = rowMeans(pick(bangs_2, bangs_4, bangs_6), na.rm = TRUE)\n  ) |&gt;\n  # Rejoin telemetry variables (no imputation needed)\n  left_join(telemetry_vars, by = c(\"pid\", \"wave\")) |&gt;\n  # Calculate person means within each imputation\n  group_by(.imp, pid) |&gt;\n  mutate(\n    global_ns_pm = mean(global_ns, na.rm = TRUE),\n    global_nf_pm = mean(global_nf, na.rm = TRUE),\n    game_ns_pm = mean(game_ns, na.rm = TRUE),\n    game_nf_pm = mean(game_nf, na.rm = TRUE)\n  ) |&gt;\n  ungroup() |&gt;\n  # Calculate grand means and centered values within each imputation\n  group_by(.imp) |&gt;\n  mutate(\n    global_ns_gm = mean(global_ns_pm, na.rm = TRUE),\n    global_nf_gm = mean(global_nf_pm, na.rm = TRUE),\n    game_ns_gm = mean(game_ns_pm, na.rm = TRUE),\n    game_nf_gm = mean(game_nf_pm, na.rm = TRUE),\n\n    # Within-person centered (deviation from person mean)\n    global_ns_cw = global_ns - global_ns_pm,\n    global_nf_cw = global_nf - global_nf_pm,\n    game_ns_cw = game_ns - game_ns_pm,\n    game_nf_cw = game_nf - game_nf_pm,\n\n    # Between-person centered (person mean - grand mean)\n    global_ns_cb = global_ns_pm - global_ns_gm,\n    global_nf_cb = global_nf_pm - global_nf_gm,\n    game_ns_cb = game_ns_pm - game_ns_gm,\n    game_nf_cb = game_nf_pm - game_nf_gm\n  ) |&gt;\n  ungroup()\n\n# Main analysis dataset: use .imp &gt; 0 (imputed datasets)\n# .imp == 0 contains the original incomplete data\ndat &lt;- daily_imputed |&gt; filter(.imp &gt; 0)\n\nmessage(glue(\n  \"Main analysis dataset: {n_distinct(dat$pid)} participants, {nrow(dat)} observations\"\n))\n\n# Create unique row ID for long format (needed for as.mids conversion)\ndaily_imputed &lt;- daily_imputed |&gt;\n  group_by(.imp) |&gt;\n  mutate(.id = row_number()) |&gt;\n  ungroup()\n\n# Helper object for mice::with() and pool() if needed\nimp_mids &lt;- as.mids(daily_imputed)"
  },
  {
    "objectID": "index.html#the-basic-needs-in-games-bang-model",
    "href": "index.html#the-basic-needs-in-games-bang-model",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "2.1 The Basic Needs in Games (BANG) Model",
    "text": "2.1 The Basic Needs in Games (BANG) Model\nThe Basic Needs in Games (BANG) model of video game play and mental health (Ballou & Deterding, 2024) builds upon the core SDT principle that any action’s impact on mental health is mediated by basic psychological needs. By differentiating between playtime and quality of play, BANG seeks to explain seemingly conflicting earlier findings that playtime itself is largely unrelated to wellbeing, but that some players do experience meaningful benefits or harms in relation to their video game play.\nTo date, however, BANG remains largely untested. Hence, the goal of this study is to test several key BANG hypotheses. We label the predictions of the current study in numerical order (e.g., H1), but also provide the numbered label from the original paper (e.g., B6) for clarity of potential falsification.\n\n2.1.1 The Relationship Between Basic Needs in Games and Global Basic Needs (H1)\nFollowing the hierarchical model of intrinsic and extrinsic motivation (Vallerand, 1997), BANG conceives of basic needs as operating at three levels of generality: situational (a particular gaming session), contextual (gaming as a whole), and global (one’s life in general). Experiences at lower levels of generality feed into and co-constitute higher levels—experiences with games are one (greater or lesser) element of one’s life overall.\nA positive relationship between need satisfaction in games and overall need satisfaction is well-established in prior literature (Allen & Anderson, 2018; Ballou, Denisova, et al., 2024; Bradt et al., 2024). BANG (B6) formalizes this relationship, proposing that need satisfaction experienced during gaming sessions contributes to overall need satisfaction in life. Thus, BANG predicts:\nH1. When individuals’ in-game needs are better satisfied, they report greater overall need satisfaction.\n\n\n2.1.2 Expectations (H2a)\nEarly articulations of SDT propose that goal or activity selection are (intrinsically) motivated by the ‘awareness of potential satisfaction’ of basic psychological needs or ‘expectations about the satisfaction of those [salient] motives’ (Deci & Ryan, 1985, pp. 231–239). Need-related outcome expectations are closely related to intrinsic motivation [perhaps even forming part of the computational machinery underlying motivation; Murayama & Jach (2023)], and the behavioral product of these expectations is therefore greater behavioral engagement.\nExpectations have , perhaps surprisingly, not featured prominently in subsequent empirical work; most gaming and media use-related SDT work focuses on need satisfaction or frustration as the experiential consequence of media consumption. This can explain loops of self-sustaining activity, but it cannot explain initial selective exposure to gaming where the activity has not commenced.\nBANG proposes that experiences of need satisfaction during a particular gaming session positively affect player’s expectations for future need satisfaction with the current game, similar games, and gaming as a whole. Outcome expectations are an important predictor of continued media engagement (Chang et al., 2014; Kocak Alan et al., 2022; Larose et al., 2001). Players report that expected need frustration is reported to modulate both initial and continued gaming exposure (Ballou & Deterding, 2023). From BANG (B8), we therefore derive the following hypothesis:\nH2a. When individuals’ in-game need satisfaction is higher, they are more likely to play video games in the 24-hour period after survey completion.\n\n\n2.1.3 Compensation (H2b)\nSDT predicts that (global) need frustration results in compensatory behavior—people attempt to replenish needs that are not being met by altering their behavior (e.g., Sheldon et al., 2011). The dense need satisfaction offered by games constitute one way for people to compensate (Ballou et al., 2022), particularly those who are highly engaged with gaming and have high gaming literacy. The combination of high need satisfaction and games and high need frustration in other life domains is often linked with increased problematic or disordered gaming, showing that compensation can occur and become maladaptive and thereby support for the so-called “need density hypothesis” (Allen & Anderson, 2018; Bradt et al., 2024; Mills et al., 2018). BANG operationalizes this compensatory play via intrinsic motivation. Frustrated needs in one’s life in general make opportunities to fulfill those needs more salient, which—all else equal—manifests phenomenologically as an increased energy towards those activities. Given this, we predict (derived from BANG Hypothesis 9):\nH2b. When individuals’ global need frustration is higher, they are more likely to play video games in the 24-hour period after survey completion.\n\n\n2.1.4 Displacement (H3)\nPlaytime, BANG argues, only becomes problematic when it displaces other activitiesessential to the maintenance of need satisfaction in life overall. Commonly proposed problematic displacements are work/school responsibilities (Drummond & Sauer, 2020), personal relationships (Domahidi et al., 2018), and physical health or sleep. Displacing activities in major life can reduce the ability to effectively engage in these areas, thereby reducing global need satisfaction. Thus, BANG (B5) predicts:\nH3. When a person’s most recent gaming displaced a core life domain (work/school, social engagements, sleep/eating/fitness, or caretaking), their global need satisfaction is lower."
  },
  {
    "objectID": "index.html#study-1-method",
    "href": "index.html#study-1-method",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "3.1 Study 1 Method",
    "text": "3.1 Study 1 Method\n\n\n\nShow code (Create platform details table)\ntibble(\n  Platform = c(\n    \"Nintendo\",\n    \"Xbox\",\n    \"Steam\"\n  ),\n  `Data Source` = c(\n    \"Data-sharing agreements with Nintendo of America\",\n    \"Data-sharing agreement with Microsoft\",\n    \"Custom web app (Gameplay.Science)\"\n  ),\n  `Account Linking Process` = c(\n    \"Participants shared an identifier contained within a QR code on the Nintendo web interface. Nintendo of America uses this identifier to retrieve gameplay data and share it with the research team.\",\n    \"Participants consented to data sharing by opting in to the study on Xbox Insiders with their Xbox account. Microsoft retrieved and shared pseudonymized gameplay data for all consented accounts.\",\n    \"Using a web app we developed (https://gameplay.science), participants consented to have their gameplay data monitored for the duration of the study. Authentication uses the official Steam API (OpenID).\"\n  ),\n  `Type of Data Collected` = c(\n    \"Session records (what game was played, at what time, for how long) for first-party games only (games published in whole or in part by Nintendo).\",\n    \"Session records (what game was played, at what time, for how long). Game titles were replaced with a random persistent identifier, but genre(s) and age ratings are shared.\",\n    \"Hourly aggregates per game (every hour, the total time spent playing each game during the previous hour)\"\n  )\n) |&gt;\n  tt(\n    escape = TRUE,\n    notes = list(\n      \"a\" = list(\n        i = 1,\n        j = 3,\n        text = \"See https://accounts.nintendo.com/qrcode.\"\n      ),\n      \"b\" = list(\n        i = 1,\n        j = 4,\n        text = \"Nintendo-published games accounted for 63% of Switch playtime in our sample.\"\n      ),\n      \"c\" = list(\n        i = 2,\n        j = 3,\n        text = \"See https://support.xbox.com/en-US/help/account-profile/manage-account/guide-to-insider-program.\"\n      )\n    )\n  ) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE, align = \"c\")\n\n\n\n\nTable 1: Platform Details\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Platform\n                Data Source\n                Account Linking Process\n                Type of Data Collected\n              \n        \n        a See https://accounts.nintendo.com/qrcode.\nb Nintendo-published games accounted for 63% of Switch playtime in our sample.\nc See https://support.xbox.com/en-US/help/account-profile/manage-account/guide-to-insider-program.\n        \n                \n                  Nintendo\n                  Data-sharing agreements with Nintendo of America\n                  Participants shared an identifier contained within a QR code on the Nintendo web interface. Nintendo of America uses this identifier to retrieve gameplay data and share it with the research team.a\n                  Session records (what game was played, at what time, for how long) for first-party games only (games published in whole or in part by Nintendo).b\n                \n                \n                  Xbox\n                  Data-sharing agreement with Microsoft\n                  Participants consented to data sharing by opting in to the study on Xbox Insiders with their Xbox account. Microsoft retrieved and shared pseudonymized gameplay data for all consented accounts.c\n                  Session records (what game was played, at what time, for how long). Game titles were replaced with a random persistent identifier, but genre(s) and age ratings are shared.\n                \n                \n                  Steam\n                  Custom web app (Gameplay.Science)\n                  Using a web app we developed (https://gameplay.science), participants consented to have their gameplay data monitored for the duration of the study. Authentication uses the official Steam API (OpenID).\n                  Hourly aggregates per game (every hour, the total time spent playing each game during the previous hour)\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n3.1.1 Design\nThe data for this study comprise a subset of the data from the Open Play study (Ballou, Földes, Vuorre, et al., 2025), version 1.0.0. In the Open Play study, participants provided access to automated records of their gaming history on one or more platforms (Xbox, Steam, Nintendo Switch, Playstation, Android), and completed an intake survey followed by a 30-day daily diary study. The intake survey included demographic questions and baseline measures of wellbeing.\nParticipants were recruited in collaboration with two panel providers, Prolific and PureProfile. Participants were eligible if they were aged 18 or older, resided in the United States, and played video games for at least 1 hour per week, of which 50% must take place on eligible platforms (Nintendo, Xbox, and Steam). Participants were required to link at least one gaming account from Xbox, Steam, or Nintendo Switch with recent telemetry data (iOS and Android data were collected but are not used in this analysis).\n\n\n3.1.2 Participants\n\n\nShow code (Calculate participant statistics and response rates)\n# Analytic sample (≥15 completions, used in imputed analyses)\nanalytic_pids &lt;- dat |&gt;\n  filter(.imp == 1) |&gt;\n  distinct(pid) |&gt;\n  pull(pid)\n\n# Prepare participant data with collapsed categories\nparticipant_data &lt;- intake |&gt;\n  filter(pid %in% c(full_eligible_pids, analytic_pids)) |&gt;\n  mutate(\n    # Collapse gender to main categories\n    gender = ifelse(\n      gender %in% c(\"Man\", \"Woman\"),\n      gender,\n      \"Other gender identity\"\n    ),\n    # Collapse ethnicity to main categories\n    ethnicity_collapsed = case_when(\n      str_detect(ethnicity, \"White\") ~ \"White\",\n      str_detect(\n        ethnicity,\n        \"Black|African American|African, Caribbean\"\n      ) ~ \"Black/African American\",\n      str_detect(ethnicity, \"Asian\") ~ \"Asian\",\n      str_detect(ethnicity, \"Two or More|Mixed\") ~ \"Multiracial\",\n      is.na(ethnicity) ~ NA_character_,\n      TRUE ~ \"Other\"\n    ),\n    # Collapse education to main levels\n    education_collapsed = case_when(\n      str_detect(\n        edu_level,\n        \"Less than|No formal|Primary\"\n      ) ~ \"Less than high school\",\n      str_detect(\n        edu_level,\n        \"High school|Secondary School|GCSE|Some college|Some University\"\n      ) ~ \"High school or some college\",\n      str_detect(edu_level, \"Associate\") ~ \"Associate degree\",\n      str_detect(\n        edu_level,\n        \"Bachelor|University Bachelors\"\n      ) ~ \"Bachelor's degree\",\n      str_detect(\n        edu_level,\n        \"Master|Graduate|professional degree|doctoral|post-graduate\"\n      ) ~ \"Graduate degree\",\n      is.na(edu_level) ~ NA_character_,\n      TRUE ~ \"Other\"\n    ),\n    # Assign to sample\n    sample = case_when(\n      pid %in% analytic_pids ~ \"Analytic sample\",\n      TRUE ~ \"Full eligible sample\"\n    )\n  ) |&gt;\n  select(\n    pid,\n    sample,\n    age,\n    gender,\n    ethnicity_collapsed,\n    education_collapsed,\n    self_reported_weekly_play,\n    diaries_completed\n  )\n\n# Sample sizes for text\nn_analytic &lt;- sum(participant_data$sample == \"Analytic sample\")\nn_full &lt;- sum(participant_data$sample == \"Full eligible sample\")\n\n# Gender summary for analytic sample (for text)\ngender_analytic &lt;- participant_data |&gt;\n  filter(sample == \"Analytic sample\") |&gt;\n  count(gender) |&gt;\n  mutate(pct = 100 * n / sum(n))\n\npct_men &lt;- gender_analytic |&gt; filter(gender == \"Man\") |&gt; pull(pct) |&gt; round(1)\npct_women &lt;- gender_analytic |&gt;\n  filter(gender == \"Woman\") |&gt;\n  pull(pct) |&gt;\n  round(1)\npct_other &lt;- gender_analytic |&gt;\n  filter(gender == \"Other gender identity\") |&gt;\n  pull(pct) |&gt;\n  round(1)\n\ngender_summary &lt;- glue(\n  \"{pct_men}% men, {pct_women}% women, {pct_other}% other gender identities\"\n)\n\n\n\n\nShow code (Generate participant demographics table)\n# Build table using map\nsummary_table &lt;- bind_rows(\n  # Sample sizes\n  tibble(\n    Characteristic = \"**N**\",\n    `Full sample` = as.character(n_full),\n    `Analytic sample` = as.character(n_analytic)\n  ),\n\n  # Age\n  tibble(\n    Characteristic = \"Age (years)\",\n    `Full sample` = format_mean_sd(\n      participant_data$age[participant_data$sample == \"Full eligible sample\"]\n    ),\n    `Analytic sample` = format_mean_sd(\n      participant_data$age[participant_data$sample == \"Analytic sample\"]\n    )\n  ),\n\n  # Categorical demographics\n  create_categorical_section(\n    participant_data,\n    \"gender\",\n    \"Gender\",\n    c(\"Man\", \"Woman\", \"Other gender identity\")\n  ),\n\n  create_categorical_section(\n    participant_data,\n    \"ethnicity_collapsed\",\n    \"Ethnicity\",\n    c(\"White\", \"Black/African American\", \"Asian\", \"Multiracial\", \"Other\")\n  ),\n\n  create_categorical_section(\n    participant_data,\n    \"education_collapsed\",\n    \"Education\",\n    c(\n      \"Less than high school\",\n      \"High school or some college\",\n      \"Associate degree\",\n      \"Bachelor's degree\",\n      \"Graduate degree\"\n    )\n  ),\n\n  # Gaming behavior section\n  tibble(\n    Characteristic = \"**Gaming behavior**\",\n    `Full sample` = \"\",\n    `Analytic sample` = \"\"\n  ),\n\n  tibble(\n    Characteristic = \"Weekly play (hours)\",\n    `Full sample` = format_mean_sd(\n      participant_data$self_reported_weekly_play[\n        participant_data$sample == \"Full eligible sample\"\n      ] /\n        60\n    ),\n    `Analytic sample` = format_mean_sd(\n      participant_data$self_reported_weekly_play[\n        participant_data$sample == \"Analytic sample\"\n      ] /\n        60\n    )\n  ),\n\n  # Study engagement section\n  tibble(\n    Characteristic = \"**Study engagement**\",\n    `Full sample` = \"\",\n    `Analytic sample` = \"\"\n  ),\n\n  tibble(\n    Characteristic = \"Surveys completed\",\n    `Full sample` = format_mean_sd(\n      participant_data$diaries_completed[\n        participant_data$sample == \"Full eligible sample\"\n      ]\n    ),\n    `Analytic sample` = format_mean_sd(\n      participant_data$diaries_completed[\n        participant_data$sample == \"Analytic sample\"\n      ]\n    )\n  )\n)\n\n# Identify rows for styling\nheader_rows &lt;- which(\n  str_detect(summary_table$Characteristic, \"^\\\\*\\\\*\") |\n    (summary_table$`Full sample` == \"\" & summary_table$`Analytic sample` == \"\")\n)\nindent_rows &lt;- which(str_detect(summary_table$Characteristic, \"^    \"))\n\n# Create table\nsummary_table |&gt;\n  tt(\n    notes = \"Values are M (SD) or N (%). Ethnicity and education categories collapsed to main levels for clarity.\"\n  ) |&gt;\n  format_tt(j = 1, markdown = TRUE) |&gt;\n  style_tt(i = header_rows, bold = TRUE) |&gt;\n  format_tt(i = header_rows, j = 1, fn = function(x) {\n    str_remove_all(x, \"\\\\*\\\\*\")\n  }) |&gt;\n  style_tt(i = indent_rows, j = 1, indent = 1) |&gt;\n  format_tt(i = indent_rows, j = 1, fn = function(x) str_trim(x)) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 2: Participant characteristics by sample\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Characteristic\n                Full sample\n                Analytic sample\n              \n        \n        Values are M (SD) or N (%). Ethnicity and education categories collapsed to main levels for clarity.\n        \n                \n                  N\n                  653\n                  555\n                \n                \n                  Age (years)\n                  25.4 (4.2)\n                  28.0 (5.2)\n                \n                \n                  Gender\n                  \n                  \n                \n                \n                  Man\n                  393 (60.2%)\n                  353 (63.6%)\n                \n                \n                  Woman\n                  225 (34.5%)\n                  159 (28.6%)\n                \n                \n                  Other gender identity\n                  35 (5.4%)\n                  43 (7.7%)\n                \n                \n                  Ethnicity\n                  \n                  \n                \n                \n                  White\n                  375 (61.5%)\n                  354 (63.8%)\n                \n                \n                  Black/African American\n                  72 (11.8%)\n                  49 (8.8%)\n                \n                \n                  Asian\n                  41 (6.7%)\n                  56 (10.1%)\n                \n                \n                  Multiracial\n                  93 (15.2%)\n                  71 (12.8%)\n                \n                \n                  Other\n                  29 (4.8%)\n                  25 (4.5%)\n                \n                \n                  Education\n                  \n                  \n                \n                \n                  Less than high school\n                  15 (2.3%)\n                  10 (1.8%)\n                \n                \n                  High school or some college\n                  360 (55.1%)\n                  242 (43.6%)\n                \n                \n                  Associate degree\n                  71 (10.9%)\n                  57 (10.3%)\n                \n                \n                  Bachelor's degree\n                  160 (24.5%)\n                  206 (37.1%)\n                \n                \n                  Graduate degree\n                  37 (5.7%)\n                  39 (7.0%)\n                \n                \n                  Gaming behavior\n                  \n                  \n                \n                \n                  Weekly play (hours)\n                  19.1 (12.5)\n                  17.7 (11.4)\n                \n                \n                  Study engagement\n                  \n                  \n                \n                \n                  Surveys completed\n                  2.8 (3.6)\n                  26.3 (3.9)\n                \n        \n      \n    \n\n\n\n\n\n\nThe analytic sample included 555 participants (63.6% men, 28.6% women, 7.7% other gender identities) who completed at least 15 daily surveys and were included in the main imputed analyses. The full eligible sample comprised 653 participants who completed at least 1 survey and were included in complete case sensitivity analyses.\n\n\n\nShow code (Create main descriptive figure)\n# Panel A: Density ridges for key variables\ndat_desc &lt;- dat |&gt; filter(.imp == 1)\n\npanel_a &lt;- dat_desc |&gt;\n  select(global_ns, global_nf, game_ns) |&gt;\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  mutate(\n    variable = factor(\n      variable,\n      levels = c(\"game_ns\", \"global_ns\", \"global_nf\"),\n      labels = c(\n        sub(\" \", \"\\n\", labels[\"game_ns\"]),\n        sub(\" \", \"\\n\", labels[\"global_ns\"]),\n        sub(\" \", \"\\n\", labels[\"global_nf\"])\n      )\n    )\n  ) |&gt;\n  ggplot(aes(x = value, y = variable, fill = variable)) +\n  geom_density_ridges(alpha = 0.7, scale = 0.9, na.rm = TRUE) +\n  scale_fill_manual(\n    values = c(\n      \"Game need\\nsatisfaction\" = colors$game_ns,\n      \"Global need\\nsatisfaction\" = colors$global_ns,\n      \"Global need\\nfrustration\" = colors$global_nf\n    )\n  ) +\n  labs(x = \"Scale Value\", y = NULL) +\n  coord_cartesian(xlim = c(1, 7)) +\n  theme(legend.position = \"none\")\n\n# Panel B: Variance decomposition\npanel_b &lt;- dat_desc |&gt;\n  select(pid, global_ns, global_nf, game_ns) |&gt;\n  pivot_longer(\n    c(global_ns, global_nf, game_ns),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |&gt;\n  group_by(variable) |&gt;\n  summarise(\n    var_total = var(value, na.rm = TRUE),\n    var_between = var(tapply(value, pid, mean, na.rm = TRUE), na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    pct_between = 100 * var_between / var_total,\n    pct_within = 100 * (var_total - var_between) / var_total,\n    variable = factor(\n      variable,\n      levels = c(\"game_ns\", \"global_ns\", \"global_nf\"),\n      labels = c(\n        sub(\" \", \"\\n\", labels[\"game_ns\"]),\n        sub(\" \", \"\\n\", labels[\"global_ns\"]),\n        sub(\" \", \"\\n\", labels[\"global_nf\"])\n      )\n    )\n  ) |&gt;\n  pivot_longer(\n    c(pct_within, pct_between),\n    names_to = \"component\",\n    values_to = \"percentage\"\n  ) |&gt;\n  mutate(\n    component = factor(\n      component,\n      levels = c(\"pct_between\", \"pct_within\"),\n      labels = c(labels[\"Between-person\"], labels[\"Within-person\"])\n    )\n  ) |&gt;\n  ggplot(aes(x = variable, y = percentage, fill = component)) +\n  geom_col(position = \"stack\") +\n  scale_fill_manual(\n    values = c(\n      \"Between-person\" = colors$between,\n      \"Within-person\" = colors$within\n    )\n  ) +\n  labs(x = NULL, y = \"Percentage of Variance\", fill = NULL) +\n  theme(legend.position = \"top\")\n\n# Panel C: Hour of day patterns\npanel_c &lt;- hourly_telemetry |&gt;\n  filter(pid %in% unique(dat_desc$pid)) |&gt;\n  mutate(hour = hour(hour_start_local)) |&gt;\n  group_by(pid, hour) |&gt;\n  summarise(total_minutes = sum(minutes, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(hour) |&gt;\n  summarise(\n    mean_minutes = mean(total_minutes, na.rm = TRUE),\n    se = sd(total_minutes, na.rm = TRUE) / sqrt(n()),\n    .groups = \"drop\"\n  ) |&gt;\n  ggplot(aes(x = hour, y = mean_minutes)) +\n  geom_ribbon(\n    aes(ymin = mean_minutes - 1.96 * se, ymax = mean_minutes + 1.96 * se),\n    fill = colors$global_nf,\n    alpha = 0.2\n  ) +\n  geom_line(color = colors$global_nf, linewidth = 1) +\n  geom_point(color = colors$global_nf, size = 2) +\n  labs(x = \"Hour of Day\", y = \"Mean Play\\n(minutes)\") +\n  scale_x_continuous(breaks = seq(0, 23, 3))\n\n# Panel D: Platform usage over study days\npanel_d &lt;- daily_telemetry |&gt;\n  mutate(day_local_date = as.Date(day_local)) |&gt;\n  inner_join(\n    dat_desc |&gt;\n      select(pid, date, wave) |&gt;\n      mutate(\n        date_only = as.Date(date),\n        wave_num = as.numeric(as.character(wave))\n      ) |&gt;\n      filter(wave_num &lt;= 30),\n    by = c(\"pid\", \"day_local_date\" = \"date_only\"),\n    relationship = \"many-to-many\"\n  ) |&gt;\n  filter(minutes &gt; 0) |&gt;\n  mutate(\n    platform = case_when(\n      platform == \"nintendo\" ~ \"Nintendo\",\n      platform == \"xbox\" ~ \"Xbox\",\n      platform == \"steam\" ~ \"Steam\",\n      TRUE ~ platform\n    )\n  ) |&gt;\n  group_by(wave_num, platform) |&gt;\n  summarise(total_minutes = sum(minutes), .groups = \"drop\") |&gt;\n  group_by(wave_num) |&gt;\n  mutate(proportion = total_minutes / sum(total_minutes)) |&gt;\n  ggplot(aes(x = wave_num, y = proportion, fill = platform)) +\n  geom_area(alpha = 0.7, position = \"stack\") +\n  scale_fill_manual(\n    values = c(\n      \"Nintendo\" = colors$nintendo,\n      \"Xbox\" = colors$xbox,\n      \"Steam\" = colors$steam\n    )\n  ) +\n  labs(x = \"Study Day\", y = \"Proportion of Play\", fill = \"Platform\") +\n  scale_x_continuous(breaks = seq(0, 30, 5)) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  theme(legend.position = \"top\")\n\n# Combine panels: top row with 3 panels, bottom row with full-width panel\n((panel_a | panel_b | panel_c) / panel_d) +\n  plot_annotation(tag_levels = \"A\") &\n  theme(\n    plot.background = element_rect(fill = \"white\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA)\n  )\n\n\n\n\n\n\n\n\nFigure 1: Descriptive statistics for key variables. (A) Distributions of need satisfaction and frustration variables. (B) Variance decomposition showing proportion of variance at within-person vs between-person levels. (C) Play volume by hour of day (local time). (D) Proportion of play on each platform across study days 1-30.\n\n\n\n\n\n\n\n\n3.1.3 Measures\n\n\nShow code (Calculate reliability for all scales)\nomega_global_ns &lt;- number(\n  omega(\n    surveys |&gt; select(bpnsfs_1, bpnsfs_3, bpnsfs_5),\n    plot = FALSE\n  )$omega.tot,\n  .01\n)\nomega_global_nf &lt;- number(\n  omega(\n    surveys |&gt; select(bpnsfs_2, bpnsfs_4, bpnsfs_6),\n    plot = FALSE\n  )$omega.tot,\n  .01\n)\n\nomega_game_ns &lt;- number(\n  omega(\n    surveys |&gt; select(bangs_1, bangs_3, bangs_5),\n    plot = FALSE\n  )$omega.tot,\n  .01\n)\nomega_game_nf &lt;- number(\n  omega(\n    surveys |&gt; select(bangs_2, bangs_4, bangs_6),\n    plot = FALSE\n  )$omega.tot,\n  .01\n)\n\n# proportion of surveys with subsequent play\n\nprop_subsequent_play &lt;- number(\n  nrow(surveys[surveys$telemetry_played_any_24h, ]) / nrow(surveys) * 100,\n  .1\n)\nminutes_subsequent_play &lt;- number(\n  mean(surveys$play_minutes_24h, na.rm = TRUE),\n  1\n)\nsd_minutes_subsequent_play &lt;- number(\n  sd(surveys$play_minutes_24h, na.rm = TRUE),\n  1\n)\n\n# total hours per platform during 30-day study period\n\nplatform_hours &lt;- daily_telemetry |&gt;\n  mutate(day_local_date = as.Date(day_local)) |&gt;\n  inner_join(\n    surveys |&gt;\n      select(pid, date, wave) |&gt;\n      distinct() |&gt;\n      mutate(\n        date_only = as.Date(date),\n        wave_num = as.numeric(as.character(wave))\n      ) |&gt;\n      filter(wave_num &lt;= 30),\n    by = c(\"pid\", \"day_local_date\" = \"date_only\"),\n    relationship = \"many-to-many\"\n  ) |&gt;\n  group_by(platform) |&gt;\n  summarise(total_hours = sum(minutes, na.rm = TRUE) / 60, .groups = \"drop\")\n\nhours_nintendo &lt;- number(\n  platform_hours |&gt; filter(platform == \"nintendo\") |&gt; pull(total_hours),\n  1\n)\nhours_xbox &lt;- number(\n  platform_hours |&gt; filter(platform == \"xbox\") |&gt; pull(total_hours),\n  1\n)\nhours_steam &lt;- number(\n  platform_hours |&gt; filter(platform == \"steam\") |&gt; pull(total_hours),\n  1\n)\n\n\nThe measures used in this paper are visualized in Figure 1 and detailed below. For other measures in the Open Play study not used here, we refer readers to the Open Play codebook available on GitHub https://digital-wellbeing.github.io/open-play/#codebook.\nNeed satisfaction in games. We measured need satisfaction and frustration in games during the most recent gaming session using 3 items from an abbreviated version of the Basic Psychological Need Satisfaction in Gaming Scale (BANGS; Ballou & Deterding (2024)). The BANGS assesses autonomy, competence, and relatedness need satisfaction with three items for each need; we selected the highest-loading item for each need for our brief daily measure. Participants rated each item on a Likert scale from 1 (Strongly disagree) to 7 (Strongly agree). We calculated mean scores for need satisfaction by averaging all three items. The reliability of the composite need satisfaction index is 0.64, and 0.65 for need frustration. As needs are conceptually distinct, we expect lower reliability for this composite index than for unidimensional scales.\nNeed satisfaction and frustration in daily life. We measured need satisfaction and frustration in daily life (“global need satisfaction and frustration”) during the previous 24 hours using the brief version of the Basic Psychological Need Satisfaction and Frustration Scale (Chen et al., 2015; Martela & Ryan, 2024). This scale includes 6 items, with one item for need satisfaction and one item for need frustration for each of the three needs. Participants rated each item on a Likert scale from 1 (Strongly disagree) to 7 (Strongly agree). We calculated mean scores for need satisfaction and need frustration by averaging the relevant items. The reliability of the composite need satisfaction index is 0.85, and 0.73 for need frustration. As needs are conceptually distinct, we expect lower reliability for this composite index than for unidimensional scales.\nVideo game play. We measured video game play using telemetry data collected from participants’ gaming accounts on Xbox, Steam, and Nintendo Switch. During the 30-day study period, we recorded a total of hours of play on Nintendo Switch, hours on Xbox, and hours on Steam. For each daily survey, we calculated total minutes played in the 24-hour period following survey completion. We also created a binary variable indicating whether any play occurred during this period. On average, 51.6% of surveys were followed by any play in the subsequent 24 hours, with a mean of 111 minutes (SD = 171).\nDisplacement: We measured displacement of core life domains via an open text field asking participants about the hypothetical alternative activity: “Think back to your most recent gaming session. If you hadn’t played a game, what would you most likely have done instead?” With LLM assistance from Qwen3-4b-instruct, we coded participant responses based on whether they mentioned any of the following activities: work/school responsibilities, social engagements, sleep/eating/fitness, or caretaking—so-called “core life domains”. We created a boolean variable indicating whether any core life domain was hypothetically displaced.\n\n\n3.1.4 Analysis Approach\nWe tested each hypothesis using a multilevel within-between linear regression with random intercepts, random slopes, and an AR(1) autocorrelation term, using the glmmTMB package (Brooks et al., 2017). Focal predictors are within-person.\n\n\n3.1.5 Imputation\nWe used multiple imputation by chained equations (MICE) with predictive mean matching (PMM) to handle missing data. Following the two-stage protocol from Von Hippel (2020) based on fraction of missing information, we used 27 imputations. For all variables, imputed distributions closely overlapped with the observed data (see Appendix Figure 6). Models were fit separately to each imputed dataset, and estimates were pooled across imputations using Rubin’s rules as implemented in the mice package (van Buuren & Groothuis-Oudshoorn, 2011). For comparison, complete case analyses are reported in the Appendix (Sensitivity Analysis 4); results do not meaningfully differ from the imputed analyses.\n\n\n3.1.6 Deviations from Preregistration\nWe made several deviations from our preregistration to ensure we could recruit enough high-quality participants to meet our sample size goals. In our view, none are so severe enough to threaten the validity of the study. Deviations are summarised in Table 3.\n\n\n\nShow code (Create table of preregistration deviations)\ntibble(\n  `Study Aspect` = c(\n    \"Data collection\",\n    \"Data collection\",\n    \"Data collection\",\n    \"Data collection\",\n    \"Data collection\",\n    \"Data collection\",\n    \"Analysis\"\n  ),\n  Preregistered = c(\n    \"All participants sourced from PureProfile\",\n    \"Screening sample would be nationally representative by ethnicity and gender\",\n    \"Sample consists of participants aged 18--30\",\n    \"To qualify, &gt;=75% of a participant's total gaming must take place on platforms included in the study (Xbox, Steam, Nintendo Switch)\",\n    \"Qualification contingent upon valid telemetry within last 7 days\",\n    \"Daily surveys sent at 7pm local time\",\n    \"Data would be imputed for all participants given a 50% overall response rate\"\n  ),\n  Actual = c(\n    \"Participants sourced from both PureProfile and Prolific\",\n    \"Approximately 50% of screening was done using quotas for national representativeness by ethnicity and gender; all subsequent sampling used convenience sampling with no quotas\",\n    \"Sample consists of participants aged 18-40\",\n    \"To qualify, &gt;=50% of a participant's total gaming must take place on platforms included in the study (Xbox, Steam, Nintendo Switch)\",\n    \"Qualification contingent upon valid telemetry within last 14 days\",\n    \"Daily surveys sent at 2pm local time\",\n    \"Data imputed for only participants with an individual 50% response rate\"\n  ),\n  `Justification for Deviation` = c(\n    \"Exhausted PureProfile participant pool before reaching required sample size\",\n    \"Exhausted participant pools of smaller demographic categories on both Prolific and PureProfile before reaching required sample size\",\n    \"(1) Unable to recruit enough participants in the US aged 18--30\",\n    \"Low rates of study qualification at 75% threshold, in large part due to substantial uncaptured Playstation play\",\n    \"Feedback from participants indicating that play during a 7-day period was subject to too many fluctuations (e.g., a busy workweek)\",\n    \"Feedback from participants indicating that evening plans often interfered with survey completion and thus adversely affected response rate\",\n    \"Imputing values for participants with 50--97% missing data is poorly justified; results from the preregistered analysis with imputation for all participants are reported in the Appendix (Sensitivity Analysis 5) and do not meaningfully differ from the main analysis\"\n  )\n) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE, align = \"c\")\n\n\n\n\nTable 3: Summary of deviations from preregistration\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Study Aspect\n                Preregistered\n                Actual\n                Justification for Deviation\n              \n        \n        \n        \n                \n                  Data collection\n                  All participants sourced from PureProfile\n                  Participants sourced from both PureProfile and Prolific\n                  Exhausted PureProfile participant pool before reaching required sample size\n                \n                \n                  Data collection\n                  Screening sample would be nationally representative by ethnicity and gender\n                  Approximately 50% of screening was done using quotas for national representativeness by ethnicity and gender; all subsequent sampling used convenience sampling with no quotas\n                  Exhausted participant pools of smaller demographic categories on both Prolific and PureProfile before reaching required sample size\n                \n                \n                  Data collection\n                  Sample consists of participants aged 18--30\n                  Sample consists of participants aged 18-40\n                  (1) Unable to recruit enough participants in the US aged 18--30\n                \n                \n                  Data collection\n                  To qualify, &gt;=75% of a participant's total gaming must take place on platforms included in the study (Xbox, Steam, Nintendo Switch)\n                  To qualify, &gt;=50% of a participant's total gaming must take place on platforms included in the study (Xbox, Steam, Nintendo Switch)\n                  Low rates of study qualification at 75% threshold, in large part due to substantial uncaptured Playstation play\n                \n                \n                  Data collection\n                  Qualification contingent upon valid telemetry within last 7 days\n                  Qualification contingent upon valid telemetry within last 14 days\n                  Feedback from participants indicating that play during a 7-day period was subject to too many fluctuations (e.g., a busy workweek)\n                \n                \n                  Data collection\n                  Daily surveys sent at 7pm local time\n                  Daily surveys sent at 2pm local time\n                  Feedback from participants indicating that evening plans often interfered with survey completion and thus adversely affected response rate\n                \n                \n                  Analysis\n                  Data would be imputed for all participants given a 50% overall response rate\n                  Data imputed for only participants with an individual 50% response rate\n                  Imputing values for participants with 50--97% missing data is poorly justified; results from the preregistered analysis with imputation for all participants are reported in the Appendix (Sensitivity Analysis 5) and do not meaningfully differ from the main analysis\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n3.1.7 Positive Controls\n\n\nShow code (Test positive controls)\n# Use first imputation for positive control check\ncor_playtime &lt;- cor.test(\n  dat$self_reported_weekly_play[dat$.imp == 1],\n  dat$play_minutes_24h[dat$.imp == 1],\n  method = \"pearson\"\n)\n\ncor_playtime_inline &lt;- glue(\n  \"r = {number(cor_playtime$estimate, .01)}, 95% CI [{number(cor_playtime$conf.int[1], .01)}, {number(cor_playtime$conf.int[2], .01)}]\"\n)\n\n\nAs specified in the preregistration, we assessed two positive controls designed to assess whether our data were capable of addressing our stated hypotheses. Both passed: self-reported playtime correlated positively with logged playtime (r = 0.28, 95% CI [0.26, 0.30]); and after preprocessing (e.g., to remove background sessions), there were no overlapping sessions. We therefore proceeded with the planned analyses.\n\n\n3.1.8 Ethics\nThis study received ethical approval from the Social Sciences and Humanities Inter-Divisional Research Ethics Committee at the University of Oxford (OII_CIA_23_107). All participants provided informed consent at the start of the study, including consent to their data being shared openly for reanalysis.\nParticipants were paid at an average rate of £12/hour, equating to: £0.20 for a 1-minute screening, £2 for the 10-minute intake survey (plus £5 for linking at least one account with recent data), £0.80 for each 4-minute daily survey. Participants received a £10 bonus payment for completing at least 24 out of 30 daily surveys."
  },
  {
    "objectID": "index.html#study-1-results-confirmatory",
    "href": "index.html#study-1-results-confirmatory",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "3.2 Study 1 Results: Confirmatory",
    "text": "3.2 Study 1 Results: Confirmatory\nWe present visualizations of marginal effects for each hypothesis test in turn; all key estimates are summarized Table 4.\n\n3.2.1 H1. Greater in-game need satisfaction is associated with greater global need satisfaction\n\n\nShow code (Fit H1 models: game NS → global NS)\n# File-based caching to avoid re-running across multiple output formats\nh1_cache_file &lt;- \"data/models/h1_fits.rds\"\nh1_pooled_file &lt;- \"data/models/h1_pooled.rds\"\n\nif (file.exists(h1_cache_file) && file.exists(h1_pooled_file)) {\n  message(\"Loading cached H1 model fits\")\n  h1_fits &lt;- readRDS(h1_cache_file)\n  h1_pooled &lt;- readRDS(h1_pooled_file)\n  h1mod &lt;- h1_fits[[1]]\n} else {\n  message(\"Fitting H1 models...\")\n\n  # Fit model to each imputed dataset\n  h1_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting H1 model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      global_ns ~ game_ns_cw +\n        game_ns_cb +\n        (1 + game_ns_cw | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i\n    )\n  })\n\n  # Pool estimates using Rubin's rules\n  h1_pooled &lt;- pool(h1_fits)\n\n  # Use first imputation's model for plotting\n  h1mod &lt;- h1_fits[[1]]\n\n  # Save results\n  dir.create(\"data/models\", showWarnings = FALSE, recursive = TRUE)\n  saveRDS(h1_fits, h1_cache_file)\n  saveRDS(h1_pooled, h1_pooled_file)\n  message(\"Saved H1 model fits to cache\")\n}\n\n\n\n\nShow code (Check H1 model diagnostics and convergence)\n# Convergence check across imputations\nconv_summary &lt;- tibble(\n  imputation = seq_along(h1_fits),\n  converged = map_lgl(h1_fits, ~ .x$fit$convergence == 0),\n  warnings = map_chr(\n    h1_fits,\n    ~ {\n      w &lt;- .x$fit$warnings\n      if (length(w) &gt; 0) paste(w, collapse = \"; \") else \"None\"\n    }\n  )\n)\nprint(conv_summary)\nglue(\"Converged: {sum(conv_summary$converged)}/{nrow(conv_summary)}\")\n\n# Random effect structure (from converged models)\nre_sd &lt;- attr(VarCorr(h1mod)$cond$pid, \"stddev\")\nglue(\"Random intercept SD: {round(re_sd[1], 3)}\")\nif (length(re_sd) &gt; 1) {\n  glue(\"Random slope SD (game_ns_cw): {round(re_sd[2], 3)}\")\n}\n\n\n\n\nShow code (Plot H1 marginal effects)\nplot_marginal_effects(\n  model = h1mod,\n  x_var = \"game_ns_cw\",\n  x_label = labels[\"game_ns\"],\n  y_label = labels[\"global_ns\"],\n  color = colors$game_ns,\n  n_keepers = 100,\n  within_vars = c(\"game_ns_cw\"),\n  between_vars = c(\"game_ns_cb\")\n)\n\n\n\n\n\n\n\n\nFigure 2: Predicted global need satisfaction as a function of need satisfaction in games. Individual trajectories shown as gray lines, population-level marginal association shown as blue line with 95% confidence ribbon.\n\n\n\n\n\nResults strongly support H1: when people felt greater need satisfaction in games than usual, they also reported greater global need satisfaction (Figure 2). On average, participants who reported 1 scale point higher need satisfaction in games than they typically did also reported 0.2383994 greater global need satisfaction, during the corresponding 24-hour period.\n\n\n3.2.2 H2. Situational need satisfaction is positively associated with the likelihood of playing in the period after survey completion (H2a), while global need frustration is negatively associated (H2b)\nWe tested H2a and H2b using a single multilevel within-between logistic regression, where in-game need satisfaction and global need frustration (each within- and between-person centered) predicted a binary variable whether any play happened in the 24-hour period after diary survey completion.\nResults support neither H2a or H2b: there is no evidence to support either hypothesis that gaming need satisfaction or global need frustration predict subsequent play (see Figure 3). We conducted a wide range of sensitivity analyses providing convergent conclusions: key estimates for gaming need satisfaction and global need frustration remain indistinguishable from 0 in models that:\n\npredict subsequent 6 or 12 hours instead of 24 hours (Sensitivity Analysis 1)\nuse alternative random slopes specifications (Sensitivity Analysis 2)\nuse a count model of minutes played in the subsequent 24 hours instead of binary play/no-play (Sensitivity Analysis 3)\nuse complete case data instead of imputed data (Sensitivity Analysis 4),\nimpute data from the full eligible sample instead of the analytic sample (Sensitivity Analysis 5)\ninclude an interaction between gaming need satisfaction and global need frustration (Sensitivity Analysis 6)\nuse a spline term for gaming need satisfaction and global need frustration, instead of a linear term (Sensitivity Analysis 7)\npredict subsequent play with each individual need (autonomy, competence, relatedness) instead of composite need satisfaction or frustration (Sensitivity Analysis 8)\n\nIn short, results consistently fail to detect an association between situational need satisfaction or global need frustration and subsequent play behaviour.\n\n\nShow code (Fit H2 models: game NS + global NF → play)\n# File-based caching to avoid re-running across multiple output formats\nh2_cache_file &lt;- \"data/models/h2_fits.rds\"\nh2_pooled_file &lt;- \"data/models/h2_pooled.rds\"\n\nif (file.exists(h2_cache_file) && file.exists(h2_pooled_file)) {\n  message(\"Loading cached H2 model fits\")\n  h2_fits &lt;- readRDS(h2_cache_file)\n  h2_pooled &lt;- readRDS(h2_pooled_file)\n  h2mod &lt;- h2_fits[[1]]\n} else {\n  message(\"Fitting H2 models...\")\n\n  # Fit model to each imputed dataset\n  # Simplified: random intercept only + AR(1) for convergence\n  h2_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting H2 model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  # Pool estimates using Rubin's rules\n  h2_pooled &lt;- pool(h2_fits)\n\n  # Use first imputation's model for plotting\n  h2mod &lt;- h2_fits[[1]]\n\n  # Save results\n  dir.create(\"data/models\", showWarnings = FALSE, recursive = TRUE)\n  saveRDS(h2_fits, h2_cache_file)\n  saveRDS(h2_pooled, h2_pooled_file)\n  message(\"Saved H2 model fits to cache\")\n}\n\n\n\n\nShow code (Check H2 model diagnostics and convergence)\n# Convergence check across imputations\nconv_summary &lt;- tibble(\n  imputation = seq_along(h2_fits),\n  converged = map_lgl(h2_fits, ~ .x$fit$convergence == 0),\n  warnings = map_chr(\n    h2_fits,\n    ~ {\n      w &lt;- .x$fit$warnings\n      if (length(w) &gt; 0) paste(w, collapse = \"; \") else \"None\"\n    }\n  )\n)\nprint(conv_summary)\nglue(\"Converged: {sum(conv_summary$converged)}/{nrow(conv_summary)}\")\n\n# Random effect structure (from converged models)\nre_sd &lt;- attr(VarCorr(h2mod)$cond$pid, \"stddev\")\nre_names &lt;- names(re_sd)\nwalk2(re_names, re_sd, ~ glue(\"{.x} SD: {round(.y, 3)}\"))\n\n# Random intercept distribution (logit scale)\nre_intercepts &lt;- coef(h2mod)$cond$pid[, \"(Intercept)\"]\ntibble(\n  stat = c(\"Mean\", \"SD\", \"Min\", \"Max\", \"IQR_25%\", \"IQR_75%\"),\n  value = c(\n    mean(re_intercepts),\n    sd(re_intercepts),\n    min(re_intercepts),\n    max(re_intercepts),\n    quantile(re_intercepts, 0.25),\n    quantile(re_intercepts, 0.75)\n  )\n) |&gt;\n  mutate(value = round(value, 3)) |&gt;\n  print()\n\n# Implied probability at fixed intercept\nfixed_int &lt;- fixef(h2mod)$cond[\"(Intercept)\"]\nglue(\"Pr(play) at population mean: {round(plogis(fixed_int), 3)}\")\n\n# DHARMa residual diagnostics\nsim_resid &lt;- simulateResiduals(h2mod, plot = FALSE)\n\n# Overall fit\nplot(sim_resid, main = \"H2 Model: DHARMa diagnostics\")\n\n# Statistical tests\nlist(\n  dispersion = testDispersion(sim_resid),\n  outliers = testOutliers(sim_resid),\n  quantiles = testQuantiles(sim_resid)\n) |&gt;\n  walk(print)\n\n# Residuals vs. predictors\npar(mfrow = c(2, 2))\nwalk2(\n  c(\"game_ns_cw\", \"global_nf_cw\", \"game_ns_cb\", \"global_nf_cb\"),\n  c(\n    labels[\"game_ns_cw\"],\n    labels[\"global_nf_cw\"],\n    labels[\"game_ns_cb\"],\n    labels[\"global_nf_cb\"]\n  ),\n  ~ plotResiduals(sim_resid, form = h2mod$frame[[.x]], main = glue(\"vs. {.y}\"))\n)\npar(mfrow = c(1, 1))\n\n# Temporal autocorrelation (within-person lag-1)\nacf_by_person &lt;- h2mod$frame |&gt;\n  group_by(pid) |&gt;\n  arrange(wave) |&gt;\n  filter(n() &gt;= 3) |&gt;\n  reframe(\n    acf = cor(\n      sim_resid$scaledResiduals[cur_group_rows()][-n()],\n      sim_resid$scaledResiduals[cur_group_rows()][-1],\n      use = \"complete.obs\"\n    )\n  ) |&gt;\n  pull(acf)\n\ntibble(\n  stat = c(\"Mean\", \"Median\", \"Min\", \"Max\"),\n  lag1_acf = c(\n    mean(acf_by_person),\n    median(acf_by_person),\n    min(acf_by_person),\n    max(acf_by_person)\n  )\n) |&gt;\n  mutate(lag1_acf = round(lag1_acf, 3)) |&gt;\n  print()\n\n# Aggregated residuals\nrecalculateResiduals(sim_resid, group = h2mod$frame$wave) |&gt;\n  plot(main = \"Residuals by wave\")\nrecalculateResiduals(sim_resid, group = h2mod$frame$pid) |&gt;\n  plot(main = \"Residuals by individual\")\n\n\n\n\n\nShow code (Plot H2 marginal effects)\n# Panel A: Game need satisfaction\np_h2a &lt;- plot_marginal_effects(\n  model = h2mod,\n  x_var = \"game_ns_cw\",\n  x_label = labels[\"game_ns\"],\n  y_label = \"Pr(played in subsequent 24h)\",\n  color = colors$game_ns,\n  n_keepers = 50,\n  within_vars = c(\"game_ns_cw\", \"global_nf_cw\"),\n  between_vars = c(\"game_ns_cb\", \"global_nf_cb\")\n)\n\n# Panel B: Global need frustration\np_h2b &lt;- plot_marginal_effects(\n  model = h2mod,\n  x_var = \"global_nf_cw\",\n  x_label = labels[\"global_nf\"],\n  y_label = \"Pr(played in subsequent 24h)\",\n  color = colors$global_nf,\n  n_keepers = 50,\n  within_vars = c(\"game_ns_cw\", \"global_nf_cw\"),\n  between_vars = c(\"game_ns_cb\", \"global_nf_cb\")\n)\n\n# Combine with patchwork and set y-axis limits to 0-100%\np_h2a +\n  p_h2b +\n  plot_annotation(tag_levels = \"A\") &\n  coord_cartesian(ylim = c(0, 1)) &\n  theme(plot.tag = element_text(face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\nFigure 3: Predicted probability of playing in subsequent 24 hours. (A) As a function of need satisfaction in games (H2a). (B) As a function of global need frustration (H2b). Individual trajectories shown as gray lines, population-level marginal associations shown with 95% confidence ribbons.\n\n\n\n\n\n\n\n\n3.2.3 H3. When gaming displaces a core life domain, global need satisfaction will be lower\n\n\nShow code (Fit H3 models: displaced core domain → global NS)\n# File-based caching to avoid re-running across multiple output formats\nh3_cache_file &lt;- \"data/models/h3_fits.rds\"\nh3_pooled_file &lt;- \"data/models/h3_pooled.rds\"\n\nif (file.exists(h3_cache_file) && file.exists(h3_pooled_file)) {\n  message(\"Loading cached H3 model fits\")\n  h3_fits &lt;- readRDS(h3_cache_file)\n  h3_pooled &lt;- readRDS(h3_pooled_file)\n  h3mod &lt;- h3_fits[[1]]\n} else {\n  message(\"Fitting H3 models...\")\n\n  # Fit model to each imputed dataset\n  h3_fits &lt;- lapply(1:m_imputations, function(i) {\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      global_ns ~ displaced_core_domain +\n        (1 + displaced_core_domain | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i\n    )\n  })\n\n  # Pool estimates using Rubin's rules\n  h3_pooled &lt;- pool(h3_fits)\n\n  # Use first imputation's model for plotting\n  h3mod &lt;- h3_fits[[1]]\n\n  # Save results\n  dir.create(\"data/models\", showWarnings = FALSE, recursive = TRUE)\n  saveRDS(h3_fits, h3_cache_file)\n  saveRDS(h3_pooled, h3_pooled_file)\n  message(\"Saved H3 model fits to cache\")\n}\n\nh3_est &lt;- number(\n  summary(h3_pooled) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"displaced_core_domainTRUE\") |&gt;\n    pull(estimate),\n  .01\n)\n\n\n\n\n\nShow code (Plot H3: displaced activity categories vs global NS)\n# Get raw data from first imputation for visualization\nh3_data &lt;- dat |&gt;\n  filter(.imp == 1, !is.na(displaced_core_domain)) |&gt;\n  mutate(\n    displacement_label = if_else(\n      displaced_core_domain,\n      \"Displaced core domain\",\n      \"Displaced non-core domain\"\n    ),\n    x_numeric = if_else(displaced_core_domain, 2, 1)\n  )\n\n# Calculate means for each group (to match what stat_histinterval will show)\nh3_means &lt;- h3_data |&gt;\n  group_by(x_numeric, displacement_label) |&gt;\n  summarise(mean_ns = mean(global_ns, na.rm = TRUE), .groups = \"drop\")\n\nggplot(h3_data, aes(x = x_numeric, y = global_ns)) +\n  # Raincloud plot with asymmetric histograms\n  stat_histinterval(\n    data = h3_data |&gt; filter(!displaced_core_domain),\n    aes(fill = displacement_label),\n    slab_alpha = 0.5,\n    point_interval = mean_qi,\n    breaks = seq(1, 7, by = .4),\n    interval_color = \"black\",\n    point_color = \"black\",\n    point_size = 3,\n    slab_fill = colors$global_ns,\n    side = \"left\"\n  ) +\n  stat_histinterval(\n    data = h3_data |&gt; filter(displaced_core_domain),\n    aes(fill = displacement_label),\n    slab_alpha = 0.5,\n    point_interval = mean_qi,\n    breaks = seq(1, 7, by = .4),\n    interval_color = \"black\",\n    point_color = \"black\",\n    point_size = 3,\n    slab_fill = colors$global_ns,\n    side = \"right\"\n  ) +\n  # Line connecting the mean point estimates\n  geom_line(\n    data = h3_means,\n    aes(x = x_numeric, y = mean_ns),\n    color = \"black\",\n    linewidth = 0.8,\n    linetype = \"solid\"\n  ) +\n  scale_x_continuous(\n    breaks = c(1, 2),\n    labels = c(\"Displaced non-core\\ndomain\", \"Displaced core\\ndomain\")\n  ) +\n  scale_y_continuous(\n    breaks = 1:7,\n    limits = c(1, 7)\n  ) +\n  labs(\n    x = NULL,\n    y = labels[\"global_ns\"]\n  ) +\n  theme(\n    axis.text.x = element_text(size = 11),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nFigure 4: Global need satisfaction when gaming displaces vs. does not displace core life domains. Raincloud plot shows distribution (histogram), mean with 95% quantile interval, and line connecting means to emphasize the negligible difference.\n\n\n\n\n\n\nParticipants reported what activity their gaming session displaced 14,041 times across the study. In 5,647 cases (40.2%), gaming displaced a core life domain: sleep, eating, or fitness (n = 2,038), social engagements (n = 302), work or school (n = 1,613), or caretaking (n = 35). Gaming most commonly displaced non-core activities such as other digital media use (n = 4,211) and other leisure activities (n = 1,297).\nResults provide very weak support for H3: on average, people who reported that their most recent gaming session displaced a core life domain reported -0.06 lower global need satisfaction. On a 7-point scale, this difference is extremely small, and the distributions of global need satisfaction when gaming displaced core vs. non-core domains are nearly identical (Figure 4).\nAn exploratory analysis (Appendix Sensitivity Analysis 10) examined whether this relationship differed for specific displaced life domains. Results showed that need satisfaction was lower when gaming displaced work/school responsibilities and sleep/eating/fitness, but—contrary to expectations—tended to be higher when gaming displaced social engagements or caretaking. We return to this in the discussion.\n\n\nShow code (Create combined results table)\n# Combine all three hypothesis results into one table\nh1_combined &lt;- summary(h1_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    Model = \"H1: game NS → global NS\",\n    term = ifelse(term %in% names(labels), labels[term], term),\n    test_stat = \"t\"\n  )\n\nh2_combined &lt;- summary(h2_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    Model = \"H2: game NS + global NF → play\",\n    term = ifelse(term %in% names(labels), labels[term], term),\n    test_stat = \"z\"\n  )\n\nh3_combined &lt;- summary(h3_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\") |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    Model = \"H3: displaced core → global NS\",\n    term = ifelse(term %in% names(labels), labels[term], term),\n    test_stat = \"t\"\n  )\n\n# Combine and format\nbind_rows(h1_combined, h2_combined, h3_combined) |&gt;\n  mutate(\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(p.value, 3))\n    ),\n    # Create combined test statistic column with appropriate label\n    test_result = glue(\"{statistic} ({test_stat})\")\n  ) |&gt;\n  select(\n    Model,\n    Parameter = term,\n    Estimate = estimate,\n    SE = std.error,\n    `Statistic` = test_result,\n    `p` = p.value\n  ) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE) |&gt;\n  group_tt(j = \"Model\")\n\n\n\n\nTable 4: Summary of main hypothesis tests (H1-H3)\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Parameter\n                Estimate\n                SE\n                Statistic\n                p\n              \n        \n        \n        \n                \n                  H1: game NS → global NS\n                  Game need frustration\n                  0.238\n                  0.017\n                  14.294 (t)\n                  &lt;.001\n                \n                \n                  H2: game NS + global NF → play\n                  Game need frustration\n                  0.042\n                  0.038\n                  1.088 (z)\n                  0.277\n                \n                \n                  H2: game NS + global NF → play\n                  Global need frustration\n                  -0.080\n                  0.043\n                  -1.864 (z)\n                  0.062\n                \n                \n                  H3: displaced core → global NS\n                  Game need frustration\n                  -0.056\n                  0.024\n                  -2.316 (t)\n                  0.021"
  },
  {
    "objectID": "index.html#study-2-method",
    "href": "index.html#study-2-method",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "4.1 Study 2 Method",
    "text": "4.1 Study 2 Method\nTo assess whether our findings generalize beyond the Open Play dataset, we examined a previously unpublished dataset from a commercial game study. These data come from PowerWash Simulator (PWS), a first-person simulation game where players use pressure washers to clean various objects (Vuorre et al., 2023). Players were prompted during gameplay to rate their experiences of autonomy, competence, focus, wellbeing, immersion, and enjoyment on 0-100 scales. We linked these ratings to objective play behavior extracted from game logs.\nThe original study procedures were granted ethical approval by Oxford University’s Central University Research Ethics Committee (SSH_OII_CIA_21_011).\n\n4.1.1 Participants\nThe characteristics of the full sample of 11,080 players in the PWS dataset are described in (Vuorre et al., 2023); here, we briefly describe the subset of data relevant to our questions. All participants were over 18 years old, provided informed consent, answered at least one mood question, and did not request their data to be deleted. The median age was 27 (19, 40; 1st and 9th deciles), and the four most frequent gender responses were Male (4,537, 52.2%), Female (2,675, 30.8%), Non-binary (723, 8.3%), and Transgender (326, 3.7%). Participants were resident in 39 countries, with the USA (4,917, 56.5%), UK (840, 9.7%), Canada (448, 5.2%), and Germany (390, 4.5%) being the most represented. Recruitment happened in multiple waves through multiple avenues inside and outside of the game. Study participation was incentivized through cosmetic in-game rewards (e.g., item skins).\n\n\n4.1.2 Measures\nPlay sessions were defined as continuous periods of activity separated by gaps in engagement of at least 30 minutes, yielding 101,602 sessions across 8,969 players. Based on the session timestamps, we calculated two behavioral outcomes: session length (minutes) and session gap (hours; defined as the end timestamp of the previous session and the start timestamp of the subsequent one).\nNeed satisfaction was measured via two in-game prompts on a visual analogue scale from 0 to 100: an autonomy item “Just now, I was doing the things I really wanted to in Powerwash Simulator” and a competence item “Just now, I felt competent playing PowerWash Simulator”, each with visual analogue scale endpoints “Not at all” and “As much as possible”. We converted each observation to a 1–10 scale for interpretability. For each session, we took the mean of all autonomy and competence ratings to generate a single need satisfaction indicator (analogously to Study 1) and decomposed it into within- and between-person components.\n\n\n4.1.3 Analysis Approach\nAnalogously to study 1, we estimated the relationship between need satisfaction and outcomes (session length, session gap) using linear mixed effects models, with random intercepts and slopes for each participant. Outcomes were log-transformed due to heavily right-skewed distributions. Following our main analysis approach, we decomposed need satisfaction predictors into within- and between-person components and controlled for previous session length and session gap to isolate need satisfaction effects.\n\n\nShow code (Fit PWS models)\n# Model 1: Session length ~ game need satisfaction\npws_m1 &lt;- lme4::lmer(\n  log(session_length) ~\n    game_ns_cw +\n    game_ns_cb +\n    prev_session_length +\n    (1 + game_ns_cw | pid),\n  data = pws_wide,\n)\n\n# Model 2: Session gap ~ game need satisfaction\npws_m2 &lt;- lme4::lmer(\n  log(session_gap) ~\n    game_ns_cw +\n    game_ns_cb +\n    prev_session_gap +\n    (1 + game_ns_cw | pid),\n  data = pws_wide |&gt; filter(!is.na(session_gap))\n)\n\npred_m1 &lt;- predictions(\n  pws_m1,\n  newdata = datagrid(\n    model = pws_m1,\n    game_ns_cw = c(0, 9),\n    game_ns_cb = 0,\n    prev_session_length = mean(pws_wide$prev_session_length, na.rm = TRUE)\n  ),\n  re.form = NA\n) |&gt;\n  as_tibble() |&gt;\n  arrange(game_ns_cw) |&gt;\n  mutate(\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high)\n  )\n\npws_m1_max_eff &lt;- pred_m1 |&gt;\n  summarise(\n    est = diff(estimate),\n    lo = diff(conf.low),\n    hi = diff(conf.high)\n  ) |&gt;\n  transmute(\n    glue(\n      \"{number(est, accuracy = 0.1)} minutes \",\n      \"[95% CI {number(lo, accuracy = 0.1)}, \",\n      \"{number(hi, accuracy = 0.1)}]\"\n    )\n  ) |&gt;\n  pull()\n\npred_m2 &lt;- predictions(\n  pws_m2,\n  newdata = datagrid(\n    model = pws_m2,\n    game_ns_cw = c(0, 9),\n    game_ns_cb = 0,\n    prev_session_gap = mean(pws_wide$prev_session_gap, na.rm = TRUE)\n  ),\n  re.form = NA\n) |&gt;\n  as_tibble() |&gt;\n  arrange(game_ns_cw) |&gt;\n  mutate(\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high)\n  )\n\npws_m2_max_eff &lt;- pred_m2 |&gt;\n  summarise(\n    est = diff(estimate),\n    lo = diff(conf.low),\n    hi = diff(conf.high)\n  ) |&gt;\n  transmute(\n    glue(\n      \"{number(est, accuracy = 0.1)} hours \",\n      \"[95% CI {number(lo, accuracy = 0.1)}, \",\n      \"{number(hi, accuracy = 0.1)}]\"\n    )\n  ) |&gt;\n  pull()\n\npws_m1_est &lt;- report_lmer_term(pws_m1, \"game_ns_cw\", p_method = \"wald_z\")\npws_m2_est &lt;- report_lmer_term(pws_m2, \"game_ns_cw\", p_method = \"wald_z\")\n\ngame_ns_sd &lt;- number(sd(pws_wide$game_ns_cw, na.rm = TRUE), .01)\n\n\n\n\n\nShow code (Visualize PWS marginal effects)\n# Generate predictions for session length\npred_m1 &lt;- marginaleffects::predictions(\n  pws_m1,\n  newdata = datagrid(\n    game_ns_cw = seq(\n      min(pws_wide$game_ns_cw, na.rm = TRUE),\n      max(pws_wide$game_ns_cw, na.rm = TRUE),\n      length.out = 100\n    ),\n    game_ns_cb = 0,\n    prev_session_length = mean(pws_wide$prev_session_length, na.rm = TRUE)\n  ),\n  re.form = NA\n) |&gt;\n  as_tibble() |&gt;\n  mutate(\n    # Back-transform from log scale to original scale (minutes)\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high)\n  )\n\n# Generate predictions for session gap\npred_m2 &lt;- marginaleffects::predictions(\n  pws_m2,\n  newdata = datagrid(\n    game_ns_cw = seq(\n      min(pws_wide$game_ns_cw, na.rm = TRUE),\n      max(pws_wide$game_ns_cw, na.rm = TRUE),\n      length.out = 100\n    ),\n    game_ns_cb = 0,\n    prev_session_gap = mean(pws_wide$prev_session_gap, na.rm = TRUE)\n  ),\n  re.form = NA\n) |&gt;\n  as_tibble() |&gt;\n  mutate(\n    # Back-transform from log scale to original scale (hours)\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high)\n  )\n\n# Panel A: Session length\np_m1 &lt;- ggplot(pred_m1, aes(x = game_ns_cw, y = estimate)) +\n  geom_ribbon(\n    aes(ymin = conf.low, ymax = conf.high),\n    alpha = 0.2,\n    fill = colors$game_ns\n  ) +\n  geom_line(color = colors$game_ns, linewidth = 1) +\n  scale_y_log10(\n    breaks = scales::breaks_log(n = 6),\n    labels = scales::label_number()\n  ) +\n  labs(\n    x = labels[\"game_ns\"],\n    y = \"Session length (minutes)\"\n  )\n\n# Panel B: Session gap\np_m2 &lt;- ggplot(pred_m2, aes(x = game_ns_cw, y = estimate)) +\n  geom_ribbon(\n    aes(ymin = conf.low, ymax = conf.high),\n    alpha = 0.2,\n    fill = colors$global_ns\n  ) +\n  geom_line(color = colors$global_ns, linewidth = 1) +\n  scale_y_log10(\n    breaks = scales::breaks_log(n = 6),\n    labels = scales::label_number()\n  ) +\n  labs(\n    x = labels[\"game_ns\"],\n    y = \"Time to next session (hours)\"\n  )\n\n# Combine panels\np_m1 +\n  p_m2 +\n  plot_annotation(tag_levels = \"A\") &\n  theme(plot.tag = element_text(face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\nFigure 5: Within-person effects of need satisfaction on play behavior in PowerWash Simulator. (A) Session length. (B) Time to next session. Shaded regions show 95% confidence intervals."
  },
  {
    "objectID": "index.html#study-2-results-exploratory",
    "href": "index.html#study-2-results-exploratory",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "4.2 Study 2 Results: Exploratory",
    "text": "4.2 Study 2 Results: Exploratory\nResults are shown in Figure 5. Panel A shows that people who felt greater need satisfaction than they normally do during the course of a gaming session did not play significantly longer than usual: if a player reported the largest possible change, a session with 10 reported need satisfaction for someone who typically reports only a 1, we would predict a change of just 5.9 minutes [95% CI -1.4, 14.2].\nPanel B shows that within-person variation in need satisfaction weakly predicted session gap. If a player reported the largest possible change in need satisfaction of 9 points, we would predict a change of just -3.7 hours [95% CI -5.6, -0.9] in time until their next session. While this is statistically significant, given that typical deviations in within-person need satisfaction are much smaller (within-person SD = 0.71 points), the practical impact on behavior is minimal.\nBroadly, results therefore converge with Study 1: Despite examining 101,602 sessions from 8,969 players in a different game using different measures, the pattern of weak behavioral predictions replicated. Full model outputs are provided in the Appendix (Table 8)."
  },
  {
    "objectID": "index.html#alternative-behavioural-frameworks",
    "href": "index.html#alternative-behavioural-frameworks",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "5.1 Alternative behavioural frameworks",
    "text": "5.1 Alternative behavioural frameworks\nThe weak associations between need experiences and subsequent play behaviour suggest that basic psychological needs may not be the primary drivers of short-term gaming engagement. In light of this, we suggest player experience research consider other theoretical frameworks that might provide better or complementary explanations for short-term gaming engagement. We are aware of least three such frameworks.\nBehaviourist and reinforcement-learning accounts emphasise the power of recent rewards and environmental cues, rather than subjective motives, in sustaining behaviour (Niv, 2009; Skinner, 1965). Recent work has expanded and adapted these predictions for the digital media domain (Norwood & Przybylski, 2025). Under such models, a primary cause of players re-engaging is that the behaviour has been reliably reinforced, not because they recently felt more autonomy, competence, or relatedness.\nHabit theory similarly predicts minimal coupling between momentary experiences and action. With sufficient repetition in stable contexts, gaming becomes cue-triggered and automatic, guided by procedural memory rather than conscious motivational states (Ouellette & Wood, 1998; Wood & Rünger, 2016). If players typically launch games at particular times or in response to specific cues, need fluctuations may exert little incremental influence over behaviour.\nA third possibility is regulatory cessation. In homeostatic and cybernetic models, behaviour is energized by need- or goal-discrepancies and should weaken once these are reduced; highly satisfying engagement may therefore decrease the likelihood of immediate re-engagement (Carver & Scheier, 2001; Hull, 1943; Toates, 1986). Self-determination theory explicitly rejects this logic for psychological needs, arguing that need satisfaction does not produce satiation or motivational decline and may instead sustain intrinsic motivation (Sheldon & Gunz, 2009). However, SDT evidence has primarily relied on self-reported motivation rather than observed behavioural continuation, potentially obscuring homeostatic or satiation-like dynamics that operate at the level of action. In games research, where engagement unfolds as repeated consumption, such regulatory processes may better account for short-term disengagement following highly satisfying play episodes.\nEach of these perspectives aligns with broader evidence that subjective intentions and experiences often predict real-world actions only weakly because behaviour is multiply determined and heavily constrained by situational affordances (Sheeran & Webb, 2016). For researchers, our findings therefore suggest that comprehensive models of gaming behaviour may need to incorporate reinforcement histories, habits, and regulatory processes alongside need-based motivations. For game developers, they suggest that relying on experiential metrics (e.g., ‘fun’, satisfaction surveys) may provide an incomplete picture of what sustains engagement. For parents and clinicians, they suggest that efforts to promote healthier play patterns may benefit from structural interventions—e.g., modifying reward pacing, friction costs, or contextual cues—rather than focusing solely on enhancing need fulfilment."
  },
  {
    "objectID": "index.html#the-value-of-open-behavioral-data",
    "href": "index.html#the-value-of-open-behavioral-data",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "5.2 The value of open behavioral data",
    "text": "5.2 The value of open behavioral data\nThe introduction to this paper outlined three key limitations in gaming research: lack of researcher access to industry data, temporal mismatch between trace data and surveys, and weak theoretical frameworks. Our study addressed all three by negotiating multi-platform access, implementing daily diaries, and testing theory-driven predictions. Yet the clearest contribution may be demonstrating what becomes visible when self-report is paired with comprehensive behavioral records.\nHad we relied solely on self-report measures of play behavior—as most media use research does—we may well have found that need satisfaction correlates with intrinsic motivation, and that therefore higher engagement is likely (Kosa & Uysal, 2024; Neys et al., 2014). The trace data reveal a different picture. This is not unique to SDT or gaming; intention-behavior gaps are well-documented across health behaviors, environmental actions, and consumer choices (Sheeran & Webb, 2016). But it is particularly consequential in a field where theoretical claims increasingly concern behavior itself—how much people play, when they play, what motivates them to start or stop.\nThe broader lesson extends beyond SDT. As gaming research matures beyond simple quantity-based approaches (Ballou, Hakman, et al., 2025), theories must be validated against behavioral outcomes, not just self-reported proxies. Open player behavior data—whether through industry partnerships, player-controlled data sharing infrastructures, or other mechanisms—is essential infrastructure for this work.\nThere are, however, practical barriers to making such behavioural evidence routine. Privacy and re-identification risks are non-trivial for high-resolution telemetry, particularly when combined with survey responses, and these risks create understandable reluctance among both participants and data holders. Industry incentives also rarely align with open scientific practices: the most informative behavioural data are often commercially sensitive, operationally costly to extract, and legally complex to share across jurisdictions. Methodologically, the field also lacks shared standards for defining sessions, handling idle time, linking multi-platform identities, and documenting preprocessing decisions—each of which can meaningfully affect substantive conclusions.\nWe therefore advocate for multi-platform solutions, mixing both open source and, where possible with high transparency standards, industry collaborations. Multi-platform coverage matters substantively because platform ecosystems structure when and how people play. Different platforms afford different play contexts (e.g., portable vs. fixed-location play, solitary vs. social defaults, friction to launch, and typical session cadence), and these affordances can shift the distribution of sessions across the day and week. When studies observe only a single platform, they risk misclassifying a person’s true “non-play” periods (e.g., apparent disengagement on one platform may simply reflect switching to another), attenuating within-person associations and obscuring displacement dynamics. Single-platform datasets also risk overgeneralizing from idiosyncratic platform cultures and technical constraints (such as background processes, suspend/resume behavior, or account sharing) that can inflate or distort behavioural measures."
  },
  {
    "objectID": "index.html#implications-for-the-bang-model",
    "href": "index.html#implications-for-the-bang-model",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "5.3 Implications for the BANG model",
    "text": "5.3 Implications for the BANG model\nOnly one of BANG’s prediction was supported (H1/B6: game needs → global needs), consistent with prior literature (Allen & Anderson, 2018; Ballou, Denisova, et al., 2024) and the proposed hierarchical structure at the core of SDT (Vallerand, 1997). However, the behavioral predictions fared poorly. Neither in-game positive experiences nor deficits in life in general meaningfully predicted subsequent play (global need frustration → subsequent play) was not supported. All in all, BANG hypotheses B5, B8, and B9 were unsupported in our data.\nNull results for theoretical predictions can generally be attributed to (1) lack of statistical power, (2) validity issues (e.g., poor design, poor measures), (3) incorrect auxiliary hypotheses, or (4) theory failure (Meehl, 1990). We argue that our study is reasonably well-powered (see Ballou, Földes, Hakman, et al., 2025 for simulated sensitivity analyses), and with the exception of H3 whose “hypothetical displacement” measure has obvious flaws (see Limitations), uses valid measures—in particular, because we observe real-world behaviour.\nWe endeavored to test the most prominent auxiliary hypothesis present, namely the auxiliary of correct timescale, by comparing 6-hour, 12-hour, and 24-hour time periods, and by triangulating using the PowerWash Simulator dataset, wherein need-related experiences are captured within the session itself. However, none were able to find meaningful support for the behavioral predictions.\nWe therefore interpret our results as evidence against certain BANG predictions, necessitating model updating. From a metascientific perspective, model updating after falsification is central to iterative model calibration and theory modulation (Meehl, 1990), in which constructs are sharpened, measurement improved, and boundary conditions more precisely articulated. Updating BANG requires identifying when and why need-related processes do and do not predict behavioral engagement.\nA wholesale revision of BANG is beyond the scope of the current paper, but our results suggest follow-up investigation should be limited to targeted probes aimed at determining whether the null results here reflect (i) temporal misalignment (for example, it may be that need satisfaction updates expectations much more gradually); (ii) boundary conditions (for example, if where need–behaviour links emerge only for specific players, games, or contexts with low constraint and weak habitual control); or (iii) competing processes (for example, if habits, reinforcement histories, and situational affordances dominate short-term behaviour, leaving needs to shape preferences rather than actions). Critically, if behavioural effects remain absent under conditions designed to maximise their detectability, BANG’s behavioural claims should be revised or removed rather than further insulated."
  },
  {
    "objectID": "index.html#limitations-and-future-directions",
    "href": "index.html#limitations-and-future-directions",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "5.4 Limitations and Future Directions",
    "text": "5.4 Limitations and Future Directions\nSeveral limitations qualify the interpretation of the present findings. First, although our analyses focus on within-person associations, these estimates should not be interpreted as causal effects (Rohrer & Murayama, 2021). Even with dense longitudinal measurement, within-person variation does not isolate exogenous change: need satisfaction may covary with unmeasured situational factors (e.g., time availability, fatigue, social context) that independently shape gaming behaviour. Our results therefore speak to the strength of empirical coupling between needs and behaviour, not to causal necessity or sufficiency.\nSecond, our test of displacement (H3) relies on a hypothetical counterfactual measure: what participants report they would have done had they not played. This approach is coarse and vulnerable to recall bias, rationalisation, and ambiguity in how respondents interpret “most likely” alternatives. While the measure provides a useful first pass at identifying potentially displaced life domains, it is ill-suited for detecting subtle or cumulative displacement processes and likely attenuates any true effects. More rigorous tests of displacement will require objective time-use data or designs that directly observe trade-offs between activities.\nThird, the behavioural outcomes examined here reflect short-term engagement patterns, such as session length and return latency. Null or weak associations at this timescale do not rule out need-related effects on longer-term outcomes, such as game choice, persistence over months, or disengagement trajectories. Our conclusions are therefore limited to short-term behavioural dynamics and should not be generalized to all forms of gaming involvement.\nFinally, our sample, although purposively sampled for racial and gender diversity, should be understood as consisting of engaged 18–40 year old players willing to share detailed behavioural data and complete intensive surveys, rather than as representative of all players. This selectivity limits generalizability in two ways. First, casual players, younger adolescents, and individuals with minimal or highly irregular play patterns are underrepresented. Second, highly engaged players’ behaviour may differ systematically from those among less engaged populations (e.g,more routinized or more highly habit-driven). The weak need–behaviour associations observed here may not generalize to all player groups, nor do they preclude stronger effects in populations with greater variability in motivation or fewer structural constraints.\nTogether, these limitations suggest that the present findings should be interpreted as strong evidence against large, general, short-term behavioural effects of need satisfaction among engaged adult players, rather than as definitive evidence against any role for psychological needs in shaping gaming behaviour more broadly."
  },
  {
    "objectID": "index.html#full-model-outputs",
    "href": "index.html#full-model-outputs",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "7.1 Full Model Outputs",
    "text": "7.1 Full Model Outputs\nThis section provides complete model summaries for the three main hypothesis tests (H1-H3), including all fixed effects (both within- and between-person), random effects, and autocorrelation parameters.\n\n7.1.1 H1: Game need satisfaction predicts global need satisfaction\n\n\nShow code (Full H1 model output)\n# Use first imputation model for complete summary\nmodelsummary(\n  list(\"H1: Game NS positively associated with Global NS\" = h1mod),\n  coef_rename = labels,\n  statistic = c(\n    \"conf.int\",\n    \"s.e. = {std.error}\",\n    \"t = {statistic}\",\n    \"p = {p.value}\"\n  ),\n  coef_omit = \"wave\", # Omit individual AR(1) wave parameters\n) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 5: H1: Complete model summary for game NS → global NS\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                H1: Game NS positively associated with Global NS\n              \n        \n        \n        \n                \n                  Intercept\n                  4.746\n                \n                \n                  \n                  [4.675, 4.817]\n                \n                \n                  \n                  s.e. = 0.036\n                \n                \n                  \n                  t = 130.605\n                \n                \n                  \n                  p = &lt;0.001\n                \n                \n                  Game need satisfaction (within)\n                  0.232\n                \n                \n                  \n                  [0.204, 0.260]\n                \n                \n                  \n                  s.e. = 0.014\n                \n                \n                  \n                  t = 16.123\n                \n                \n                  \n                  p = &lt;0.001\n                \n                \n                  Game need satisfaction (between)\n                  0.860\n                \n                \n                  \n                  [0.767, 0.953]\n                \n                \n                  \n                  s.e. = 0.047\n                \n                \n                  \n                  t = 18.164\n                \n                \n                  \n                  p = &lt;0.001\n                \n                \n                  SD (Intercept pid)\n                  0.820\n                \n                \n                  SD (game_ns_cw pid)\n                  0.206\n                \n                \n                  Cor (Intercept~game_ns_cw pid)\n                  0.044\n                \n                \n                  SD (Observations)\n                  0.792\n                \n                \n                  Num.Obs.\n                  11239\n                \n                \n                  R2 Marg.\n                  0.424\n                \n                \n                  AIC\n                  30324.9\n                \n                \n                  BIC\n                  30390.8\n                \n                \n                  RMSE\n                  0.71\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.1.2 H2: Need satisfaction and frustration predict subsequent play\n\n\nShow code (Full H2 model output)\n# Use first imputation model for complete summary\n# modelsummary(\n#   h2mod,\n#   coef_rename = labels,\n#   statistic = c(\n#     \"conf.int\",\n#     \"s.e. = {std.error}\",\n#     \"t = {statistic}\",\n#     \"p = {p.value}\"\n#   ),\n#   coef_omit = \"wave\", # Omit individual AR(1) wave parameters\n# ) |&gt;\n#   style_tt(fontsize = 0.7) |&gt;\n#   style_tt(i = 0, bold = TRUE)\n\n## 1) Pre-tidy with CIs\ntt &lt;- tidy(h2mod, effects = \"fixed\", conf.int = TRUE)\n\n## 2) Optional: rename coefficients manually now\ntt &lt;- tt |&gt;\n  mutate(\n    term = dplyr::recode(term, !!!labels)\n  )\n\n## 3) Pre-compute glance once\ngl &lt;- glance(h2mod)\n\n## 4) Wrap as a modelsummary_list (no further introspection)\nmod_obj &lt;- structure(\n  list(\n    tidy = tt,\n    glance = gl\n  ),\n  class = \"modelsummary_list\"\n)\n\n## 5) Now call modelsummary on this object\nmodelsummary(\n  list(\"H2: NS & NF associated with likelihood of subsequent play\" = mod_obj),\n  statistic = c(\n    \"CI = [{conf.low}, {conf.high}]\",\n    \"s.e. = {std.error}\",\n    \"z = {statistic}\",\n    \"p = {p.value}\"\n  ),\n  coef_omit = \"wave\",\n) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 6: H2: Complete model summary for game NS + global NF → play\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                H2: NS & NF associated with likelihood of subsequent play\n              \n        \n        \n        \n                \n                  Intercept\n                  0.632\n                \n                \n                  \n                  CI = [0.404, 0.860]\n                \n                \n                  \n                  s.e. = 0.116\n                \n                \n                  \n                  z = 5.439\n                \n                \n                  \n                  p = &lt;0.001\n                \n                \n                  Game need satisfaction (within)\n                  0.042\n                \n                \n                  \n                  CI = [-0.033, 0.117]\n                \n                \n                  \n                  s.e. = 0.038\n                \n                \n                  \n                  z = 1.098\n                \n                \n                  \n                  p = 0.272\n                \n                \n                  Game need satisfaction (between)\n                  0.057\n                \n                \n                  \n                  CI = [-0.273, 0.386]\n                \n                \n                  \n                  s.e. = 0.168\n                \n                \n                  \n                  z = 0.338\n                \n                \n                  \n                  p = 0.736\n                \n                \n                  Global need frustration (within)\n                  -0.079\n                \n                \n                  \n                  CI = [-0.163, 0.005]\n                \n                \n                  \n                  s.e. = 0.043\n                \n                \n                  \n                  z = -1.847\n                \n                \n                  \n                  p = 0.065\n                \n                \n                  Global need frustration (between)\n                  0.080\n                \n                \n                  \n                  CI = [-0.190, 0.351]\n                \n                \n                  \n                  s.e. = 0.138\n                \n                \n                  \n                  z = 0.581\n                \n                \n                  \n                  p = 0.561\n                \n                \n                  Num.Obs.\n                  10317\n                \n                \n                  AIC\n                  9726.2\n                \n                \n                  BIC\n                  9784.1\n                \n                \n                  Log.Lik.\n                  -4855.107\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.1.3 H3: Displacing core domains predicts lower global need satisfaction\n\n\nShow code (Full H3 model output)\n# Use first imputation model for complete summary\nmodelsummary(\n  list(\n    \"H3: Displacement of core life domain associated with lower Global NF\" = h3mod\n  ),\n  coef_rename = labels,\n  statistic = c(\n    \"conf.int\",\n    \"s.e. = {std.error}\",\n    \"t = {statistic}\",\n    \"p = {p.value}\"\n  ),\n  coef_omit = \"wave\", # Omit individual AR(1) wave parameters\n) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 7: H3: Complete model summary for displaced core → global NS\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                H3: Displacement of core life domain associated with lower Global NF\n              \n        \n        \n        \n                \n                  Intercept\n                  4.753\n                \n                \n                  \n                  [4.662, 4.843]\n                \n                \n                  \n                  s.e. = 0.046\n                \n                \n                  \n                  t = 102.550\n                \n                \n                  \n                  p = &lt;0.001\n                \n                \n                  Displaced core domain\n                  -0.048\n                \n                \n                  \n                  [-0.090, -0.007]\n                \n                \n                  \n                  s.e. = 0.021\n                \n                \n                  \n                  t = -2.271\n                \n                \n                  \n                  p = 0.023\n                \n                \n                  SD (Intercept pid)\n                  1.043\n                \n                \n                  SD (displaced_core_domainTRUE pid)\n                  0.054\n                \n                \n                  Cor (Intercept~displaced_core_domainTRUE pid)\n                  -0.052\n                \n                \n                  SD (Observations)\n                  0.815\n                \n                \n                  Num.Obs.\n                  12686\n                \n                \n                  R2 Marg.\n                  0.001\n                \n                \n                  AIC\n                  35301.8\n                \n                \n                  BIC\n                  35361.4\n                \n                \n                  RMSE\n                  0.72\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.1.4 Study 2: Game need satisfaction predicts play behavior\n\n\nShow code (Full Study 2 model output)\n# Create model summaries for both Study 2 models\nmodelsummary(\n  list(\n    \"Session Length\" = pws_m1,\n    \"Time to Next Session\" = pws_m2\n  ),\n  coef_rename = labels,\n  statistic = c(\n    \"conf.int\",\n    \"s.e. = {std.error}\",\n    \"t = {statistic}\",\n    \"p = {p.value}\"\n  )\n) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 8: Study 2: Complete model summaries for game NS → play behavior\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Session Length\n                Time to Next Session\n              \n        \n        \n        \n                \n                  Intercept\n                  4.218\n                  2.414\n                \n                \n                  \n                  [4.202, 4.233]\n                  [2.376, 2.451]\n                \n                \n                  \n                  s.e. = 0.008\n                  s.e. = 0.019\n                \n                \n                  \n                  t = 530.451\n                  t = 125.734\n                \n                \n                  \n                  p = &lt;0.001\n                  p = &lt;0.001\n                \n                \n                  Game need satisfaction (within)\n                  0.009\n                  -0.044\n                \n                \n                  \n                  [-0.003, 0.021]\n                  [-0.082, -0.005]\n                \n                \n                  \n                  s.e. = 0.006\n                  s.e. = 0.020\n                \n                \n                  \n                  t = 1.409\n                  t = -2.235\n                \n                \n                  \n                  p = 0.159\n                  p = 0.025\n                \n                \n                  Game need satisfaction (between)\n                  0.011\n                  -0.009\n                \n                \n                  \n                  [0.003, 0.019]\n                  [-0.035, 0.016]\n                \n                \n                  \n                  s.e. = 0.004\n                  s.e. = 0.013\n                \n                \n                  \n                  t = 2.555\n                  t = -0.722\n                \n                \n                  \n                  p = 0.011\n                  p = 0.471\n                \n                \n                  prev_session_length\n                  0.001\n                  \n                \n                \n                  \n                  [0.001, 0.001]\n                  \n                \n                \n                  \n                  s.e. = 0.000\n                  \n                \n                \n                  \n                  t = 14.287\n                  \n                \n                \n                  \n                  p = &lt;0.001\n                  \n                \n                \n                  prev_session_gap\n                  \n                  0.000\n                \n                \n                  \n                  \n                  [0.000, 0.000]\n                \n                \n                  \n                  \n                  s.e. = 0.000\n                \n                \n                  \n                  \n                  t = 7.113\n                \n                \n                  \n                  \n                  p = &lt;0.001\n                \n                \n                  SD (Intercept pid)\n                  0.234\n                  0.701\n                \n                \n                  SD (game_ns_cw pid)\n                  0.028\n                  0.159\n                \n                \n                  Cor (Intercept~game_ns_cw pid)\n                  -0.441\n                  0.118\n                \n                \n                  SD (Observations)\n                  0.649\n                  1.896\n                \n                \n                  Num.Obs.\n                  22742\n                  20724\n                \n                \n                  R2 Marg.\n                  0.010\n                  0.003\n                \n                \n                  R2 Cond.\n                  0.124\n                  0.125\n                \n                \n                  AIC\n                  242285.4\n                  185815.0\n                \n                \n                  BIC\n                  242349.6\n                  185878.5\n                \n                \n                  ICC\n                  0.1\n                  0.1\n                \n                \n                  RMSE\n                  0.63\n                  1.83"
  },
  {
    "objectID": "index.html#diagnostics",
    "href": "index.html#diagnostics",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "7.2 Diagnostics",
    "text": "7.2 Diagnostics\n\n\nShow code\n# Compare observed vs imputed distributions (pooled across waves)\ndaily_imputed |&gt;\n  pivot_longer(\n    c(global_ns, global_nf, game_ns),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |&gt;\n  filter(!is.na(value)) |&gt;\n  mutate(\n    data_type = if_else(.imp == 0, \"Observed\", \"Imputed\"),\n    data_type = factor(data_type, levels = c(\"Observed\", \"Imputed\")),\n    variable = factor(\n      variable,\n      levels = c(\"game_ns\", \"global_ns\", \"global_nf\"),\n      labels = c(labels[\"game_ns\"], labels[\"global_ns\"], labels[\"global_nf\"])\n    )\n  ) |&gt;\n  ggplot(aes(x = value, color = data_type, group = .imp)) +\n  geom_density(linewidth = 0.7) +\n  scale_color_manual(\n    values = c(\"Observed\" = \"black\", \"Imputed\" = \"steelblue\")\n  ) +\n  facet_wrap(~variable, scales = \"free\", nrow = 1) +\n  labs(color = NULL, x = \"Value\", y = \"Density\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 6: Imputed vs observed distributions for need satisfaction/frustration variables"
  },
  {
    "objectID": "index.html#sensitivity-analyses",
    "href": "index.html#sensitivity-analyses",
    "title": "All BANG, little buck: Need-related experiences are weak predictors of behaviour in the video game domain",
    "section": "7.3 Sensitivity Analyses",
    "text": "7.3 Sensitivity Analyses\nWe conducted several sensitivity analyses to assess the robustness of our findings regarding the relationship between need satisfaction/frustration and subsequent play behavior.\n\n7.3.1 S1: Temporal window robustness\nTesting whether the temporal window affects results. The main analysis used 24 hours post-survey. Here we test: (a) 12 hours post-survey, (b) 6 hours post-survey, and (c) 24 hours pre-survey (reverse temporal ordering to test bidirectionality).\n\n\nShow code (S1: Fit models with 12-hour play window)\n# File-based caching to avoid re-running across multiple output formats\nsens1_cache_file &lt;- \"data/models/sens1_fits.rds\"\nsens1_pooled_file &lt;- \"data/models/sens1_pooled.rds\"\n\nif (file.exists(sens1_cache_file) && file.exists(sens1_pooled_file)) {\n  message(\"Loading cached S1 model fits\")\n  sens1_fits &lt;- readRDS(sens1_cache_file)\n  sens1_pooled &lt;- readRDS(sens1_pooled_file)\n} else {\n  message(\"Fitting S1 models...\")\n\n  sens1_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S1 model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_12h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  sens1_pooled &lt;- pool(sens1_fits)\n\n  # Save to cache\n  saveRDS(sens1_fits, sens1_cache_file)\n  saveRDS(sens1_pooled, sens1_pooled_file)\n  message(\"S1 models saved to cache\")\n}\n\n\n\n\nShow code (S1b: Fit models with 6-hour play window)\n# File-based caching to avoid re-running across multiple output formats\nsens1b_cache_file &lt;- \"data/models/sens1b_fits.rds\"\nsens1b_pooled_file &lt;- \"data/models/sens1b_pooled.rds\"\n\nif (file.exists(sens1b_cache_file) && file.exists(sens1b_pooled_file)) {\n  message(\"Loading cached S1b model fits\")\n  sens1b_fits &lt;- readRDS(sens1b_cache_file)\n  sens1b_pooled &lt;- readRDS(sens1b_pooled_file)\n} else {\n  message(\"Fitting S1b models...\")\n\n  sens1b_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S1b model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_6h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  sens1b_pooled &lt;- pool(sens1b_fits)\n\n  # Save to cache\n  saveRDS(sens1b_fits, sens1b_cache_file)\n  saveRDS(sens1b_pooled, sens1b_pooled_file)\n  message(\"S1b models saved to cache\")\n}\n\n\n\n\nShow code (S1c: Fit models with 24-hour pre-survey play window)\n# File-based caching to avoid re-running across multiple output formats\nsens1c_cache_file &lt;- \"data/models/sens1c_fits.rds\"\nsens1c_pooled_file &lt;- \"data/models/sens1c_pooled.rds\"\n\nif (file.exists(sens1c_cache_file) && file.exists(sens1c_pooled_file)) {\n  message(\"Loading cached S1c model fits\")\n  sens1c_fits &lt;- readRDS(sens1c_cache_file)\n  sens1c_pooled &lt;- readRDS(sens1c_pooled_file)\n} else {\n  message(\"Fitting S1c models...\")\n\n  sens1c_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S1c model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h_pre ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  sens1c_pooled &lt;- pool(sens1c_fits)\n\n  # Save to cache\n  saveRDS(sens1c_fits, sens1c_cache_file)\n  saveRDS(sens1c_pooled, sens1c_pooled_file)\n  message(\"S1c models saved to cache\")\n}\n\n\n\n\nShow code (Create combined temporal windows table)\n# Combine all results\nbind_rows(\n  clean_results(h2_pooled, \"24h post\"),\n  clean_results(sens1_pooled, \"12h post\"),\n  clean_results(sens1b_pooled, \"6h post\"),\n  clean_results(sens1c_pooled, \"24h pre\")\n) |&gt;\n  pivot_wider(\n    names_from = window,\n    values_from = result,\n    names_sort = FALSE\n  ) |&gt;\n  rename(Parameter = term) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 9: S1: H2 associations across different temporal windows. Main analysis (24h post-survey) shown for comparison. Pre-survey window tests reverse temporal ordering.\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                24h post\n                12h post\n                6h post\n                24h pre\n              \n        \n        \n        \n                \n                  Game need frustration\n                  0.042 (0.277)\n                  0.04 (0.235)\n                  0.043 (0.19)\n                  0.14 (&lt;.001)\n                \n                \n                  Global need frustration\n                  -0.08 (0.062)\n                  -0.016 (0.668)\n                  -0.012 (0.751)\n                  -0.081 (0.07)\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.2 S2: Random effects specification robustness\nRandom slopes allow associations to vary across individuals, which is theoretically appropriate for these constructs. The main analysis used a random intercept only model due to convergence issues in frequentist estimation. Here we test whether this simplification affects fixed effect estimates by comparing four specifications: (a) no random slopes (main model), (b) random slope for game NS within-person only, (c) random slope for global NF within-person only, and (d) both random slopes simultaneously using Bayesian estimation (which handles complex random effects more robustly).\n\n\nShow code (S2: Fit Bayesian model with random slopes)\n# File-based caching to avoid re-running across multiple output formats\nsens2_cache_file &lt;- \"data/models/sens2_fit.rds\"\n\nif (file.exists(sens2_cache_file)) {\n  message(\"Loading cached S2 model fit\")\n  sens2_fit &lt;- readRDS(sens2_cache_file)\n} else {\n  message(\"Fitting S2 Bayesian model...\")\n\n  # Use complete cases only\n  dat_complete &lt;- daily_imputed |&gt;\n    filter(\n      .imp == 0,\n      !is.na(global_ns),\n      !is.na(global_nf),\n      !is.na(game_ns),\n      !is.na(game_nf),\n      !is.na(telemetry_played_any_24h)\n    )\n\n  # Fit Bayesian model with random slopes\n  sens2_fit &lt;- brm(\n    telemetry_played_any_24h ~\n      game_ns_cw +\n      game_ns_cb +\n      global_nf_cw +\n      global_nf_cb +\n      (1 + game_ns_cw + global_nf_cw | pid),\n    family = bernoulli(),\n    data = dat_complete,\n    chains = 4,\n    cores = 4,\n    iter = 5000,\n    warmup = 1000,\n    seed = 8675309\n  )\n\n  # Save to cache\n  saveRDS(sens2_fit, sens2_cache_file)\n  message(\"S2 model saved to cache\")\n}\n\n\n\n\nShow code (S2: Fit H2 models with one random slope at a time)\n# File-based caching to avoid re-running across multiple output formats\nsens2_h2a_cache &lt;- \"data/models/sens2_h2a_fits.rds\"\nsens2_h2a_pooled_cache &lt;- \"data/models/sens2_h2a_pooled.rds\"\nsens2_h2b_cache &lt;- \"data/models/sens2_h2b_fits.rds\"\nsens2_h2b_pooled_cache &lt;- \"data/models/sens2_h2b_pooled.rds\"\n\nif (\n  file.exists(sens2_h2a_cache) &&\n    file.exists(sens2_h2a_pooled_cache) &&\n    file.exists(sens2_h2b_cache) &&\n    file.exists(sens2_h2b_pooled_cache)\n) {\n  message(\"Loading cached S2 one-slope model fits\")\n  s2_h2a_fits &lt;- readRDS(sens2_h2a_cache)\n  s2_h2a_pooled &lt;- readRDS(sens2_h2a_pooled_cache)\n  s2_h2b_fits &lt;- readRDS(sens2_h2b_cache)\n  s2_h2b_pooled &lt;- readRDS(sens2_h2b_pooled_cache)\n} else {\n  message(\"Fitting S2 one-slope models...\")\n\n  # H2a: Random slope for game_ns_cw only\n  message(\"Fitting S2 H2a models...\")\n  s2_h2a_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S2 H2a model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 + game_ns_cw | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  s2_h2a_pooled &lt;- pool(s2_h2a_fits)\n\n  # H2b: Random slope for global_nf_cw only\n  message(\"Fitting S2 H2b models...\")\n  s2_h2b_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S2 H2b model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 + global_nf_cw | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  s2_h2b_pooled &lt;- pool(s2_h2b_fits)\n\n  # Save to cache\n  saveRDS(s2_h2a_fits, sens2_h2a_cache)\n  saveRDS(s2_h2a_pooled, sens2_h2a_pooled_cache)\n  saveRDS(s2_h2b_fits, sens2_h2b_cache)\n  saveRDS(s2_h2b_pooled, sens2_h2b_pooled_cache)\n  message(\"S2 one-slope models saved to cache\")\n}\n\n\n\n\nShow code (Create S2 combined specification comparison table)\n# Extract estimates from main H2 model (no random slopes)\nh2_simple &lt;- summary(h2_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(\n    term %in% c(\"game_ns_cw\", \"global_nf_cw\")\n  ) |&gt;\n  mutate(\n    result = glue(\n      \"{round(estimate, 3)} ({ifelse(p.value &lt; 0.001, '&lt;.001', round(p.value, 3))})\"\n    )\n  ) |&gt;\n  select(term, result) |&gt;\n  mutate(specification = \"No slopes\")\n\n# Extract estimates from one-slope models\nh2a_est &lt;- summary(s2_h2a_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(\n    term %in% c(\"game_ns_cw\", \"global_nf_cw\")\n  ) |&gt;\n  mutate(\n    result = glue(\n      \"{round(estimate, 3)} ({ifelse(p.value &lt; 0.001, '&lt;.001', round(p.value, 3))})\"\n    )\n  ) |&gt;\n  select(term, result) |&gt;\n  mutate(specification = \"RS: game NS\")\n\nh2b_est &lt;- summary(s2_h2b_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(\n    term %in% c(\"game_ns_cw\", \"global_nf_cw\")\n  ) |&gt;\n  mutate(\n    result = glue(\n      \"{round(estimate, 3)} ({ifelse(p.value &lt; 0.001, '&lt;.001', round(p.value, 3))})\"\n    )\n  ) |&gt;\n  select(term, result) |&gt;\n  mutate(specification = \"RS: global NF\")\n\n# Extract estimates from Bayesian model with both slopes\nsens2_est &lt;- summary(sens2_fit)$fixed |&gt;\n  as_tibble(rownames = \"term\") |&gt;\n  filter(\n    term %in% c(\"game_ns_cw\", \"global_nf_cw\")\n  ) |&gt;\n  mutate(\n    # Bayesian doesn't have p-values, show 95% CI instead\n    result = glue(\n      \"{round(Estimate, 3)} [{round(`l-95% CI`, 3)}, {round(`u-95% CI`, 3)}]\"\n    )\n  ) |&gt;\n  select(term, result) |&gt;\n  mutate(specification = \"Both slopes (Bayesian)\")\n\n# Combine all specifications\nbind_rows(h2_simple, h2a_est, h2b_est, sens2_est) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term)\n  ) |&gt;\n  pivot_wider(names_from = specification, values_from = result) |&gt;\n  rename(Parameter = term) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 10: S2: H2 fixed effect estimates across random effects specifications. Frequentist estimates (first three columns) show estimate (p-value). Bayesian estimates show estimate [95% credible interval].\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                No slopes\n                RS: game NS\n                RS: global NF\n                Both slopes (Bayesian)\n              \n        \n        \n        \n                \n                  Game need satisfaction (within)\n                  0.042 (0.277)\n                  0.036 (0.362)\n                  0.043 (0.266)\n                  0.039 [-0.034, 0.111]\n                \n                \n                  Global need frustration (within)\n                  -0.08 (0.062)\n                  -0.08 (0.063)\n                  -0.079 (0.093)\n                  -0.063 [-0.153, 0.028]\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.3 S3: Play volume (continuous outcome)\nTesting whether the predictors have a linear association with play volume in minutes, rather than binary play occurrence. Uses Gaussian family for continuous outcome.\n\n\nShow code (S3: Fit models predicting continuous play volume)\n# File-based caching to avoid re-running across multiple output formats\nsens3_cache_file &lt;- \"data/models/sens3_fits.rds\"\nsens3_pooled_file &lt;- \"data/models/sens3_pooled.rds\"\n\nif (file.exists(sens3_cache_file) && file.exists(sens3_pooled_file)) {\n  message(\"Loading cached S3 model fits\")\n  sens3_fits &lt;- readRDS(sens3_cache_file)\n  sens3_pooled &lt;- readRDS(sens3_pooled_file)\n} else {\n  message(\"Fitting S3 models...\")\n\n  # Fit model to each imputed dataset\n  sens3_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S3 model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      play_minutes_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = gaussian()\n    )\n  })\n\n  sens3_pooled &lt;- pool(sens3_fits)\n\n  # Save to cache\n  saveRDS(sens3_fits, sens3_cache_file)\n  saveRDS(sens3_pooled, sens3_pooled_file)\n  message(\"S3 models saved to cache\")\n}\n\n\n\n\nShow code (Create S5 results table)\nsummary(sens3_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term),\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(p.value, 3))\n    )\n  ) |&gt;\n  rename(\n    Parameter = term,\n    Estimate = estimate,\n    SE = std.error,\n    t = statistic,\n    p = p.value\n  ) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 11: S3: H2 predicting continuous play volume (minutes)\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Estimate\n                SE\n                t\n                p\n              \n        \n        \n        \n                \n                  Game need frustration\n                  0.042\n                  0.038\n                  1.081\n                  0.28\n                \n                \n                  Global need frustration\n                  -0.076\n                  0.043\n                  -1.755\n                  0.079\n                \n                \n                  Time to next session\n                  0.038\n                  0.041\n                  0.921\n                  0.357\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.4 S4: Complete cases only (no imputation)\nTesting whether multiple imputation introduced bias. Main analysis used MICE with PMM; here we analyze only complete cases.\n\n\nShow code (S4: Fit models on complete cases only)\n# File-based caching to avoid re-running across multiple output formats\nsens4_cache_file &lt;- \"data/models/sens4_fit.rds\"\n\nif (file.exists(sens4_cache_file)) {\n  message(\"Loading cached S4 model fit\")\n  sens4_fit &lt;- readRDS(sens4_cache_file)\n} else {\n  message(\"Fitting S4 model...\")\n\n  # Use .imp == 0 (original data with missingness)\n  # Filter to complete cases on key variables\n  dat_complete &lt;- daily_imputed |&gt;\n    filter(\n      .imp == 0,\n      !is.na(global_ns),\n      !is.na(global_nf),\n      !is.na(game_ns),\n      !is.na(game_nf),\n      !is.na(telemetry_played_any_24h)\n    )\n\n  sens4_fit &lt;- glmmTMB(\n    telemetry_played_any_24h ~\n      game_ns_cw +\n      game_ns_cb +\n      global_nf_cw +\n      global_nf_cb +\n      (1 | pid) +\n      ar1(wave + 0 | pid),\n    data = dat_complete,\n    family = binomial(link = \"logit\"),\n    ziformula = ~0\n  )\n\n  # Save to cache\n  saveRDS(sens4_fit, sens4_cache_file)\n  message(\"S4 model saved to cache\")\n}\n\n\n\n\nShow code (Create S4 results table)\nsummary(sens4_fit)$coefficients$cond |&gt;\n  as_tibble(rownames = \"term\") |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, Estimate, `Std. Error`, `z value`, `Pr(&gt;|z|)`) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term),\n    across(c(Estimate, `Std. Error`, `z value`), ~ round(.x, 3)),\n    `Pr(&gt;|z|)` = case_when(\n      `Pr(&gt;|z|)` &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(`Pr(&gt;|z|)`, 3))\n    )\n  ) |&gt;\n  rename(Parameter = term, SE = `Std. Error`, z = `z value`, p = `Pr(&gt;|z|)`) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 12: S4: H2 with complete cases only (no imputation)\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Estimate\n                SE\n                z\n                p\n              \n        \n        \n        \n                \n                  Game need satisfaction (within)\n                  0.042\n                  0.038\n                  1.096\n                  0.273\n                \n                \n                  Global need frustration (within)\n                  -0.077\n                  0.043\n                  -1.797\n                  0.072\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.5 S5: Full sample imputation (preregistered approach)\nMain analysis imputed analytical sample only (≥15 waves, N~555) for statistical soundness. Preregistration specified imputing all participants. Here we implement that approach for comparison, though note that imputing 80%+ missing data for sparse participants is statistically questionable.\n\n\nShow code (S5: Run imputation on full sample)\n# Set M for full sample imputation (can be lower for testing)\nM_FULL_SAMPLE &lt;- 3 # Set to 27 for final run\n\nmessage(\"=== FULL SAMPLE IMPUTATION (PREREGISTERED) ===\")\nmessage(glue(\n  \"Imputing all {length(full_eligible_pids)} participants with M={M_FULL_SAMPLE}\"\n))\n\n# Separate telemetry (no missing data) - use full sample\ntelemetry_vars_full &lt;- surveys |&gt;\n  select(\n    pid,\n    wave,\n    date,\n    telemetry_played_any_24h,\n    play_minutes_24h,\n    telemetry_played_any_12h,\n    play_minutes_12h,\n    telemetry_played_any_6h,\n    play_minutes_6h,\n    telemetry_played_any_24h_pre,\n    play_minutes_24h_pre\n  )\n\n# Convert to wide format for imputation - NO FILTER\nsurveys_wide_full &lt;- surveys |&gt;\n  select(\n    pid,\n    wave,\n    age,\n    gender,\n    edu_level,\n    employment,\n    marital_status,\n    life_sat_baseline,\n    wemwbs,\n    diaries_completed,\n    self_reported_weekly_play,\n    self_reported_played_24h,\n    displaced_core_domain,\n    bpnsfs_1,\n    bpnsfs_2,\n    bpnsfs_3,\n    bpnsfs_4,\n    bpnsfs_5,\n    bpnsfs_6,\n    bangs_1,\n    bangs_2,\n    bangs_3,\n    bangs_4,\n    bangs_5,\n    bangs_6\n  ) |&gt;\n  pivot_wider(\n    id_cols = c(\n      pid,\n      age,\n      gender,\n      edu_level,\n      employment,\n      marital_status,\n      life_sat_baseline,\n      wemwbs,\n      diaries_completed,\n      self_reported_weekly_play\n    ),\n    names_from = wave,\n    values_from = c(\n      self_reported_played_24h,\n      displaced_core_domain,\n      bpnsfs_1,\n      bpnsfs_2,\n      bpnsfs_3,\n      bpnsfs_4,\n      bpnsfs_5,\n      bpnsfs_6,\n      bangs_1,\n      bangs_2,\n      bangs_3,\n      bangs_4,\n      bangs_5,\n      bangs_6\n    ),\n    names_sep = \"_w\"\n  )\n\n# Set up imputation methods (same as analytical sample)\nplayed_vars_full &lt;- names(surveys_wide_full)[grepl(\n  \"^self_reported_played_24h_w\",\n  names(surveys_wide_full)\n)]\nbpnsfs_vars_full &lt;- names(surveys_wide_full)[grepl(\n  \"^bpnsfs_[1-6]_w\",\n  names(surveys_wide_full)\n)]\nbangs_vars_full &lt;- names(surveys_wide_full)[grepl(\n  \"^bangs_[1-6]_w\",\n  names(surveys_wide_full)\n)]\ndisplaced_vars_full &lt;- names(surveys_wide_full)[grepl(\n  \"^displaced_core_domain_w\",\n  names(surveys_wide_full)\n)]\n\nmethods_full &lt;- setNames(\n  rep(\"\", ncol(surveys_wide_full)),\n  names(surveys_wide_full)\n)\nmethods_full[played_vars_full] &lt;- \"logreg\"\nmethods_full[c(bpnsfs_vars_full, bangs_vars_full, displaced_vars_full)] &lt;- \"pmm\"\n\nperson_level_vars &lt;- c(\n  \"pid\",\n  \"age\",\n  \"gender\",\n  \"edu_level\",\n  \"employment\",\n  \"marital_status\",\n  \"life_sat_baseline\",\n  \"wemwbs\",\n  \"diaries_completed\",\n  \"self_reported_weekly_play\"\n)\nmethods_full[person_level_vars] &lt;- \"\"\n\n# Create WHERE matrix (same conditional imputation logic)\nwhere_matrix_full &lt;- is.na(surveys_wide_full)\n\nfor (bangs_var in bangs_vars_full) {\n  wave_num &lt;- str_extract(bangs_var, \"\\\\d+$\")\n  played_var &lt;- paste0(\"self_reported_played_24h_w\", wave_num)\n\n  if (played_var %in% names(surveys_wide_full)) {\n    no_play &lt;- surveys_wide_full[[played_var]] == \"No\" &\n      is.na(surveys_wide_full[[bangs_var]])\n    where_matrix_full[no_play, bangs_var] &lt;- FALSE\n  }\n}\n\n# Sparse predictor matrix (same settings as analytical)\npred_full &lt;- quickpred(\n  surveys_wide_full,\n  mincor = 0.3,\n  minpuc = 0.3,\n  include = c(\"age\", \"wemwbs\", \"self_reported_weekly_play\"),\n  exclude = c(\n    \"pid\",\n    \"gender\",\n    \"edu_level\",\n    \"employment\",\n    \"marital_status\",\n    \"diaries_completed\"\n  )\n)\n\n# Check if imputation already exists\nimp_file_full &lt;- \"data/imputation_full.csv.gz\"\n\nif (file.exists(imp_file_full)) {\n  message(glue(\"Loading existing full sample imputation from {imp_file_full}\"))\n  imp_long_full &lt;- read_csv(imp_file_full, show_col_types = FALSE)\n  imp_full &lt;- as.mids(imp_long_full)\n  message(glue(\"Loaded imputation object (M={imp_full$m})\"))\n} else {\n  message(glue(\"No existing imputation found - running MICE on full sample\"))\n\n  message(glue(\n    \"Running MICE: M={M_FULL_SAMPLE}, N={nrow(surveys_wide_full)}, started {Sys.time()}\"\n  ))\n\n  imp_full &lt;- futuremice(\n    data = surveys_wide_full,\n    m = M_FULL_SAMPLE,\n    method = methods_full,\n    predictorMatrix = pred_full,\n    where = where_matrix_full,\n    maxit = 5,\n    n.core = parallel::detectCores() - 1,\n    parallelseed = 8675309\n  )\n\n  message(glue(\"Completed {Sys.time()}\"))\n\n  # Save imputation results\n  imp_long_full &lt;- complete(imp_full, action = \"long\", include = TRUE)\n  write_csv(imp_long_full, imp_file_full)\n  message(glue(\"Saved full sample imputation to {imp_file_full}\"))\n\n  if (nrow(imp_full$loggedEvents) &gt; 0) {\n    message(glue(\n      \"Warning: {nrow(imp_full$loggedEvents)} logged events during full sample imputation\"\n    ))\n  }\n}\n\n# Post-imputation processing for full sample\ndaily_imputed_full &lt;- complete(imp_full, action = \"long\", include = TRUE) |&gt;\n  pivot_longer(\n    cols = -c(\n      .imp,\n      .id,\n      pid,\n      age,\n      gender,\n      edu_level,\n      employment,\n      marital_status,\n      life_sat_baseline,\n      wemwbs,\n      diaries_completed,\n      self_reported_weekly_play\n    ),\n    names_to = c(\".value\", \"wave\"),\n    names_pattern = \"(.+)_w(.+)\"\n  ) |&gt;\n  mutate(wave = as.factor(wave)) |&gt;\n  mutate(\n    global_ns = rowMeans(pick(bpnsfs_1, bpnsfs_3, bpnsfs_5), na.rm = TRUE),\n    global_nf = rowMeans(pick(bpnsfs_2, bpnsfs_4, bpnsfs_6), na.rm = TRUE),\n    game_ns = rowMeans(pick(bangs_1, bangs_3, bangs_5), na.rm = TRUE),\n    game_nf = rowMeans(pick(bangs_2, bangs_4, bangs_6), na.rm = TRUE)\n  ) |&gt;\n  left_join(telemetry_vars_full, by = c(\"pid\", \"wave\")) |&gt;\n  group_by(.imp, pid) |&gt;\n  mutate(\n    global_ns_pm = mean(global_ns, na.rm = TRUE),\n    global_nf_pm = mean(global_nf, na.rm = TRUE),\n    game_ns_pm = mean(game_ns, na.rm = TRUE),\n    game_nf_pm = mean(game_nf, na.rm = TRUE)\n  ) |&gt;\n  ungroup() |&gt;\n  group_by(.imp) |&gt;\n  mutate(\n    global_ns_gm = mean(global_ns_pm, na.rm = TRUE),\n    global_nf_gm = mean(global_nf_pm, na.rm = TRUE),\n    game_ns_gm = mean(game_ns_pm, na.rm = TRUE),\n    game_nf_gm = mean(game_nf_pm, na.rm = TRUE),\n    global_ns_cw = global_ns - global_ns_pm,\n    global_nf_cw = global_nf - global_nf_pm,\n    game_ns_cw = game_ns - game_ns_pm,\n    game_nf_cw = game_nf - game_nf_pm,\n    global_ns_cb = global_ns_pm - global_ns_gm,\n    global_nf_cb = global_nf_pm - global_nf_gm,\n    game_ns_cb = game_ns_pm - game_ns_gm,\n    game_nf_cb = game_nf_pm - game_nf_gm\n  ) |&gt;\n  ungroup()\n\nmessage(glue(\n  \"Full sample imputation complete: {length(unique(daily_imputed_full$pid))} participants\"\n))\n\n\n\n\nShow code (S5: Fit H2 models to full sample)\n# File-based caching\nsens5_cache_file &lt;- \"data/models/sens5_fits.rds\"\nsens5_pooled_file &lt;- \"data/models/sens5_pooled.rds\"\n\nif (file.exists(sens5_cache_file) && file.exists(sens5_pooled_file)) {\n  message(\"Loading cached S5 model fits\")\n  sens5_fits &lt;- readRDS(sens5_cache_file)\n  sens5_pooled &lt;- readRDS(sens5_pooled_file)\n} else {\n  message(\"Fitting S5 models to full sample...\")\n\n  # Prepare data for modeling\n  dat_full &lt;- daily_imputed_full |&gt;\n    filter(.imp &gt; 0) |&gt;\n    mutate(\n      pid = factor(pid),\n      wave = factor(wave)\n    )\n\n  # Fit H2 model to each imputed dataset\n  sens5_fits &lt;- lapply(1:M_FULL_SAMPLE, function(i) {\n    message(glue(\"Fitting S5 model to imputation {i} of {M_FULL_SAMPLE}\"))\n    dat_i &lt;- dat_full |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  # Pool estimates\n  sens5_pooled &lt;- pool(sens5_fits)\n\n  # Save to cache\n  saveRDS(sens5_fits, sens5_cache_file)\n  saveRDS(sens5_pooled, sens5_pooled_file)\n  message(\"S5 models saved to cache\")\n}\n\n\n\n\nShow code (Create S7 comparison table)\n# Analytical sample results\nanalytical &lt;- summary(h2_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  mutate(\n    result = glue(\n      \"{round(estimate, 3)} ({ifelse(p.value &lt; 0.001, '&lt;.001', round(p.value, 3))})\"\n    ),\n    sample = \"Analytical (≥15 waves)\"\n  ) |&gt;\n  select(term, sample, result)\n\n# Full sample results\nfull_sample &lt;- summary(sens5_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  mutate(\n    result = glue(\n      \"{round(estimate, 3)} ({ifelse(p.value &lt; 0.001, '&lt;.001', round(p.value, 3))})\"\n    ),\n    sample = \"Full sample\"\n  ) |&gt;\n  select(term, sample, result)\n\n# Combine\nbind_rows(analytical, full_sample) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term)\n  ) |&gt;\n  pivot_wider(names_from = sample, values_from = result) |&gt;\n  rename(Parameter = term) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 13: S7: H2 model comparison between analytical sample (≥15 waves) and full sample (preregistered)\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Analytical (≥15 waves)\n                Full sample\n              \n        \n        \n        \n                \n                  Game need frustration\n                  0.042 (0.277)\n                  2.756 (0.09)\n                \n                \n                  Global need frustration\n                  -0.08 (0.062)\n                  -1.776 (0.335)\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.6 S6: Interaction between game NS and global NF\nTesting whether the association of global need frustration with play depends on recent game need satisfaction (i.e., do satisfied players respond differently to global need frustration?).\n\n\nShow code (S6: Fit models with game NS × global NF interaction)\n# File-based caching to avoid re-running across multiple output formats\nsens6_cache_file &lt;- \"data/models/sens6_fits.rds\"\nsens6_pooled_file &lt;- \"data/models/sens6_pooled.rds\"\n\nif (file.exists(sens6_cache_file) && file.exists(sens6_pooled_file)) {\n  message(\"Loading cached S6 model fits\")\n  sens6_fits &lt;- readRDS(sens6_cache_file)\n  sens6_pooled &lt;- readRDS(sens6_pooled_file)\n} else {\n  message(\"Fitting S6 models...\")\n\n  sens6_fits &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Fitting S6 model to imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n    glmmTMB(\n      telemetry_played_any_24h ~\n        game_ns_cw +\n        game_ns_cb +\n        global_nf_cw +\n        global_nf_cb +\n        game_ns_cw:global_nf_cw +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat_i,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  })\n\n  sens6_pooled &lt;- pool(sens6_fits)\n\n  # Save to cache\n  saveRDS(sens6_fits, sens6_cache_file)\n  saveRDS(sens6_pooled, sens6_pooled_file)\n  message(\"S6 models saved to cache\")\n}\n\n\n\n\nShow code (Create S3 results table)\nsummary(sens6_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term),\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(p.value, 3))\n    )\n  ) |&gt;\n  rename(\n    Parameter = term,\n    Estimate = estimate,\n    SE = std.error,\n    z = statistic,\n    p = p.value\n  ) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 14: S6: H2 with game NS × global NF interaction\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Estimate\n                SE\n                z\n                p\n              \n        \n        \n        \n                \n                  Game need frustration\n                  0.042\n                  0.038\n                  1.081\n                  0.28\n                \n                \n                  Global need frustration\n                  -0.076\n                  0.043\n                  -1.755\n                  0.079\n                \n                \n                  Time to next session\n                  0.038\n                  0.041\n                  0.921\n                  0.357\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.7 S7: Non-linearity test with splines\nTesting whether the relationships between predictors and play behavior are non-linear by fitting natural splines to the H2 predictors. We use complete cases only (no imputation) for computational simplicity.\n\n\nShow code (S7: Fit H2 model with natural splines)\n# Use complete cases only (no imputation)\n# Create this outside caching so it's available for plotting\ndat_complete &lt;- dat |&gt;\n  filter(.imp == 1) |&gt;\n  select(\n    pid,\n    wave,\n    date,\n    telemetry_played_any_24h,\n    game_ns_cw,\n    game_ns_cb,\n    global_nf_cw,\n    global_nf_cb\n  ) |&gt;\n  filter(complete.cases(pick(everything())))\n\n# File-based caching\nsens7_linear_file &lt;- \"data/models/sens7_linear.rds\"\nsens7_spline_file &lt;- \"data/models/sens7_spline.rds\"\n\nif (file.exists(sens7_linear_file) && file.exists(sens7_spline_file)) {\n  message(\"Loading cached S7 models\")\n  sens7_linear &lt;- readRDS(sens7_linear_file)\n  sens7_spline &lt;- readRDS(sens7_spline_file)\n} else {\n  message(\"Fitting S7 models (linear vs spline)...\")\n\n  # Linear model (for comparison)\n  sens7_linear &lt;- glmmTMB(\n    telemetry_played_any_24h ~\n      game_ns_cw +\n      game_ns_cb +\n      global_nf_cw +\n      global_nf_cb +\n      (1 | pid) +\n      ar1(factor(wave) + 0 | pid),\n    data = dat_complete,\n    family = binomial(link = \"logit\")\n  )\n\n  # Spline model with natural splines (3 df) on within-person predictors\n  sens7_spline &lt;- glmmTMB(\n    telemetry_played_any_24h ~\n      ns(game_ns_cw, df = 3) +\n      game_ns_cb +\n      ns(global_nf_cw, df = 3) +\n      global_nf_cb +\n      (1 | pid) +\n      ar1(factor(wave) + 0 | pid),\n    data = dat_complete,\n    family = binomial(link = \"logit\")\n  )\n\n  # Cache results\n  dir.create(\"data/models\", showWarnings = FALSE, recursive = TRUE)\n  saveRDS(sens7_linear, sens7_linear_file)\n  saveRDS(sens7_spline, sens7_spline_file)\n}\n\n\n\n\nShow code (Create S8 comparison table)\n# Compare model fit\ncomparison &lt;- tibble(\n  Model = c(\"Linear\", \"Spline (3 df)\"),\n  AIC = c(AIC(sens7_linear), AIC(sens7_spline)),\n  BIC = c(BIC(sens7_linear), BIC(sens7_spline)),\n  LogLik = c(logLik(sens7_linear), logLik(sens7_spline)),\n  N = c(nobs(sens7_linear), nobs(sens7_spline))\n) |&gt;\n  mutate(\n    `ΔAic` = AIC - min(AIC),\n    across(c(AIC, BIC, LogLik), ~ round(.x, 1))\n  )\n\ncomparison |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 15: S7: Model comparison between linear and spline specifications\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Model\n                AIC\n                BIC\n                LogLik\n                N\n                ΔAic\n              \n        \n        \n        \n                \n                  Linear\n                  9726.2\n                  9784.1\n                  -4855.1\n                  10317\n                  0.000000\n                \n                \n                  Spline (3 df)\n                  9730.9\n                  9817.8\n                  -4853.4\n                  10317\n                  4.640006\n                \n        \n      \n    \n\n\n\n\n\n\n\n\nShow code (Plot S8 spline vs linear predictions)\n# Generate predictions across the range of predictors\npred_data &lt;- expand_grid(\n  game_ns_cw = seq(\n    min(dat_complete$game_ns_cw, na.rm = TRUE),\n    max(dat_complete$game_ns_cw, na.rm = TRUE),\n    length.out = 100\n  ),\n  global_nf_cw = seq(\n    min(dat_complete$global_nf_cw, na.rm = TRUE),\n    max(dat_complete$global_nf_cw, na.rm = TRUE),\n    length.out = 100\n  )\n)\n\n# Predictions for game NS (holding global NF at mean)\npred_game_linear &lt;- marginaleffects::predictions(\n  sens7_linear,\n  newdata = datagrid(\n    game_ns_cw = unique(pred_data$game_ns_cw),\n    global_nf_cw = 0,\n    game_ns_cb = 0,\n    global_nf_cb = 0\n  ),\n  re.form = NA,\n  type = \"response\"\n) |&gt;\n  as_tibble() |&gt;\n  mutate(model = \"Linear\")\n\npred_game_spline &lt;- marginaleffects::predictions(\n  sens7_spline,\n  newdata = datagrid(\n    game_ns_cw = unique(pred_data$game_ns_cw),\n    global_nf_cw = 0,\n    game_ns_cb = 0,\n    global_nf_cb = 0\n  ),\n  re.form = NA,\n  type = \"response\"\n) |&gt;\n  as_tibble() |&gt;\n  mutate(model = \"Spline\")\n\npanel_a &lt;- bind_rows(pred_game_linear, pred_game_spline) |&gt;\n  ggplot(aes(x = game_ns_cw, y = estimate, color = model, fill = model)) +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, color = NA) +\n  geom_line(aes(linetype = model), linewidth = 1) +\n  scale_color_manual(values = c(\"Linear\" = \"#4477AA\", \"Spline\" = \"#EE6677\")) +\n  scale_fill_manual(values = c(\"Linear\" = \"#4477AA\", \"Spline\" = \"#EE6677\")) +\n  scale_linetype_manual(values = c(\"Linear\" = \"solid\", \"Spline\" = \"dashed\")) +\n  labs(\n    x = labels[\"game_ns (within-person)\"],\n    y = \"P(Play in next 24h)\",\n    color = NULL,\n    fill = NULL,\n    linetype = NULL\n  ) +\n  theme(legend.position = \"top\")\n\n# Predictions for global NF (holding game NS at mean)\npred_nf_linear &lt;- marginaleffects::predictions(\n  sens7_linear,\n  newdata = datagrid(\n    game_ns_cw = 0,\n    global_nf_cw = unique(pred_data$global_nf_cw),\n    game_ns_cb = 0,\n    global_nf_cb = 0\n  ),\n  re.form = NA,\n  type = \"response\"\n) |&gt;\n  as_tibble() |&gt;\n  mutate(model = \"Linear\")\n\npred_nf_spline &lt;- marginaleffects::predictions(\n  sens7_spline,\n  newdata = datagrid(\n    game_ns_cw = 0,\n    global_nf_cw = unique(pred_data$global_nf_cw),\n    game_ns_cb = 0,\n    global_nf_cb = 0\n  ),\n  re.form = NA,\n  type = \"response\"\n) |&gt;\n  as_tibble() |&gt;\n  mutate(model = \"Spline\")\n\npanel_b &lt;- bind_rows(pred_nf_linear, pred_nf_spline) |&gt;\n  ggplot(aes(x = global_nf_cw, y = estimate, color = model, fill = model)) +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, color = NA) +\n  geom_line(aes(linetype = model), linewidth = 1) +\n  scale_color_manual(values = c(\"Linear\" = \"#4477AA\", \"Spline\" = \"#EE6677\")) +\n  scale_fill_manual(values = c(\"Linear\" = \"#4477AA\", \"Spline\" = \"#EE6677\")) +\n  scale_linetype_manual(values = c(\"Linear\" = \"solid\", \"Spline\" = \"dashed\")) +\n  labs(\n    x = labels[\"global_nf (within-person)\"],\n    y = \"P(Play in next 24h)\",\n    color = NULL,\n    fill = NULL,\n    linetype = NULL\n  ) +\n  theme(legend.position = \"top\")\n\npanel_a +\n  panel_b +\n  plot_annotation(tag_levels = \"A\") +\n  plot_layout(guides = \"collect\") &\n  theme(\n    legend.position = \"top\",\n    plot.background = element_rect(fill = \"white\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA)\n  )\n\n\n\n\n\n\n\n\nFigure 7: S7: Comparison of linear vs spline predictions for H2 predictors. Points show observed data (aggregated), solid lines show linear model predictions, dashed lines show spline model predictions with 95% confidence ribbons.\n\n\n\n\n\nThe spline model does not improve fit over the linear model (ΔAIC &gt; 2), suggesting that the relationships between need satisfaction/frustration and play behavior are adequately captured by linear terms.\n\n\n7.3.8 S8: Separate needs components\nTesting whether associations with play differ across the three basic psychological needs (autonomy, competence, relatedness) rather than using composite need satisfaction scores. We test H2 separately for each need component.\n\n\nShow code (Prepare data with separate needs components)\n# File-based caching to avoid re-running across multiple output formats\nsens8_cache_file &lt;- \"data/models/sens8_models.rds\"\n\nif (file.exists(sens8_cache_file)) {\n  message(\"Loading cached S8 model fits\")\n  sens8_cached &lt;- readRDS(sens8_cache_file)\n  sens8_h2_aut &lt;- sens8_cached$h2_aut\n  sens8_h2_com &lt;- sens8_cached$h2_com\n  sens8_h2_rel &lt;- sens8_cached$h2_rel\n} else {\n  message(\"Fitting S8 models...\")\n\n  # Prepare component-level data for each imputation\n  sens8_data &lt;- lapply(1:m_imputations, function(i) {\n    message(glue(\"Preparing S6 data for imputation {i} of {m_imputations}\"))\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n\n    # Calculate person means for each component (game and global)\n    dat_i &lt;- dat_i |&gt;\n      group_by(pid) |&gt;\n      mutate(\n        # Game needs\n        game_aut_pm = mean(bangs_1, na.rm = TRUE),\n        game_com_pm = mean(bangs_3, na.rm = TRUE),\n        game_rel_pm = mean(bangs_5, na.rm = TRUE),\n        # Global need frustration\n        global_aut_nf_pm = mean(bpnsfs_2, na.rm = TRUE),\n        global_com_nf_pm = mean(bpnsfs_4, na.rm = TRUE),\n        global_rel_nf_pm = mean(bpnsfs_6, na.rm = TRUE)\n      ) |&gt;\n      ungroup() |&gt;\n      # Calculate grand means\n      mutate(\n        # Game needs\n        game_aut_gm = mean(game_aut_pm, na.rm = TRUE),\n        game_com_gm = mean(game_com_pm, na.rm = TRUE),\n        game_rel_gm = mean(game_rel_pm, na.rm = TRUE),\n        # Global need frustration\n        global_aut_nf_gm = mean(global_aut_nf_pm, na.rm = TRUE),\n        global_com_nf_gm = mean(global_com_nf_pm, na.rm = TRUE),\n        global_rel_nf_gm = mean(global_rel_nf_pm, na.rm = TRUE)\n      ) |&gt;\n      # Within/between centering\n      mutate(\n        # Game needs\n        game_aut_cw = bangs_1 - game_aut_pm,\n        game_aut_cb = game_aut_pm - game_aut_gm,\n        game_com_cw = bangs_3 - game_com_pm,\n        game_com_cb = game_com_pm - game_com_gm,\n        game_rel_cw = bangs_5 - game_rel_pm,\n        game_rel_cb = game_rel_pm - game_rel_gm,\n        # Global need frustration\n        global_aut_nf_cw = bpnsfs_2 - global_aut_nf_pm,\n        global_aut_nf_cb = global_aut_nf_pm - global_aut_nf_gm,\n        global_com_nf_cw = bpnsfs_4 - global_com_nf_pm,\n        global_com_nf_cb = global_com_nf_pm - global_com_nf_gm,\n        global_rel_nf_cw = bpnsfs_6 - global_rel_nf_pm,\n        global_rel_nf_cb = global_rel_nf_pm - global_rel_nf_gm\n      )\n\n    return(dat_i)\n  })\n\n  # H2 models: game component + matching global NF component → play\n  message(\"Fitting S8 H2 autonomy models...\")\n  sens8_h2_aut &lt;- pool(lapply(sens8_data, function(dat) {\n    glmmTMB(\n      telemetry_played_any_24h ~ game_aut_cw +\n        global_aut_nf_cw +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  }))\n\n  message(\"Fitting S8 H2 competence models...\")\n  sens8_h2_com &lt;- pool(lapply(sens8_data, function(dat) {\n    glmmTMB(\n      telemetry_played_any_24h ~ game_com_cw +\n        global_com_nf_cw +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  }))\n\n  message(\"Fitting S8 H2 relatedness models...\")\n  sens8_h2_rel &lt;- pool(lapply(sens8_data, function(dat) {\n    glmmTMB(\n      telemetry_played_any_24h ~ game_rel_cw +\n        global_rel_nf_cw +\n        (1 | pid) +\n        ar1(wave + 0 | pid),\n      data = dat,\n      family = binomial(link = \"logit\"),\n      ziformula = ~0\n    )\n  }))\n\n  # Save to cache\n  saveRDS(\n    list(\n      h2_aut = sens8_h2_aut,\n      h2_com = sens8_h2_com,\n      h2_rel = sens8_h2_rel\n    ),\n    sens8_cache_file\n  )\n  message(\"S8 models saved to cache\")\n}\n\n\n\n\nShow code (Create S8 results table)\n# Extract within-person effects for both game and global needs from each model\nbind_rows(\n  summary(sens8_h2_aut) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"game_aut_cw\") |&gt;\n    mutate(predictor = \"Game autonomy\"),\n  summary(sens8_h2_aut) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"global_aut_nf_cw\") |&gt;\n    mutate(predictor = \"Global autonomy frustration\"),\n  summary(sens8_h2_com) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"game_com_cw\") |&gt;\n    mutate(predictor = \"Game competence\"),\n  summary(sens8_h2_com) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"global_com_nf_cw\") |&gt;\n    mutate(predictor = \"Global competence frustration\"),\n  summary(sens8_h2_rel) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"game_rel_cw\") |&gt;\n    mutate(predictor = \"Game relatedness\"),\n  summary(sens8_h2_rel) |&gt;\n    as_tibble() |&gt;\n    filter(term == \"global_rel_nf_cw\") |&gt;\n    mutate(predictor = \"Global relatedness frustration\")\n) |&gt;\n  mutate(\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(p.value, 3))\n    )\n  ) |&gt;\n  select(\n    Predictor = predictor,\n    Estimate = estimate,\n    SE = std.error,\n    z = statistic,\n    p = p.value\n  ) |&gt;\n  tt(\n    notes = \"All predictors are within-person effects. Outcome: Probability of playing in subsequent 24 hours.\"\n  ) |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 16: S8: Within-person associations between need components and probability of subsequent play\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Predictor\n                Estimate\n                SE\n                z\n                p\n              \n        \n        All predictors are within-person effects. Outcome: Probability of playing in subsequent 24 hours.\n        \n                \n                  Game autonomy\n                  -0.009\n                  0.032\n                  -0.290\n                  0.772\n                \n                \n                  Global autonomy frustration\n                  -0.051\n                  0.030\n                  -1.734\n                  0.083\n                \n                \n                  Game competence\n                  0.050\n                  0.028\n                  1.818\n                  0.069\n                \n                \n                  Global competence frustration\n                  -0.068\n                  0.028\n                  -2.392\n                  0.017\n                \n                \n                  Game relatedness\n                  0.021\n                  0.023\n                  0.934\n                  0.35\n                \n                \n                  Global relatedness frustration\n                  0.005\n                  0.034\n                  0.160\n                  0.873\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n7.3.9 S9: Game need frustration predicting play\nTesting whether game need frustration (rather than satisfaction) predicts subsequent play behavior. This mirrors the H2a hypothesis but uses frustration instead of satisfaction.\n\n\nShow code (S9: Fit model with game NF predicting play)\n# File-based caching\nsens9_cache_file &lt;- \"data/models/sens9_fits.rds\"\nsens9_pooled_file &lt;- \"data/models/sens9_pooled.rds\"\n\nif (file.exists(sens9_pooled_file)) {\n  message(\"Loading cached S9 pooled results\")\n  sens9_pooled &lt;- readRDS(sens9_pooled_file)\n} else {\n  message(\"Fitting S9 models...\")\n\n  # Prepare data with game_nf centered\n  sens9_data &lt;- lapply(1:m_imputations, function(i) {\n    dat_i &lt;- dat |&gt; filter(.imp == i)\n\n    dat_i |&gt;\n      group_by(pid) |&gt;\n      mutate(\n        game_nf_pm = mean(game_nf, na.rm = TRUE)\n      ) |&gt;\n      ungroup() |&gt;\n      mutate(\n        game_nf_gm = mean(game_nf_pm, na.rm = TRUE),\n        game_nf_cw = game_nf - game_nf_pm,\n        game_nf_cb = game_nf_pm - game_nf_gm\n      )\n  })\n\n  # Fit models\n  sens9_fits &lt;- lapply(sens9_data, function(dat_i) {\n    glmmTMB::glmmTMB(\n      telemetry_played_any_24h ~\n        game_nf_cw +\n        game_nf_cb +\n        (1 | pid),\n      family = binomial(link = \"logit\"),\n      data = dat_i,\n      control = glmmTMBControl(\n        optimizer = optim,\n        optArgs = list(method = \"BFGS\")\n      )\n    )\n  })\n\n  # Pool results\n  sens9_pooled &lt;- pool(sens9_fits)\n\n  # Save to cache\n  saveRDS(sens9_fits, sens9_cache_file)\n  saveRDS(sens9_pooled, sens9_pooled_file)\n  message(\"S9 models saved to cache\")\n}\n\n\n\n\nShow code (Create S10 results table)\nsummary(sens9_pooled) |&gt;\n  as_tibble() |&gt;\n  filter(term != \"(Intercept)\", !str_detect(term, \"_cb\")) |&gt;\n  select(term, estimate, std.error, statistic, p.value) |&gt;\n  mutate(\n    term = ifelse(term %in% names(labels), labels[term], term),\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      TRUE ~ as.character(round(p.value, 3))\n    )\n  ) |&gt;\n  rename(\n    Parameter = term,\n    Estimate = estimate,\n    SE = std.error,\n    z = statistic,\n    p = p.value\n  ) |&gt;\n  tt() |&gt;\n  style_tt(fontsize = 0.7) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 17: S9: Game need frustration predicting subsequent play\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Estimate\n                SE\n                z\n                p\n              \n        \n        \n        \n                \n                  Game need frustration\n                  -0.07\n                  0.035\n                  -2.009\n                  0.045\n                \n        \n      \n    \n\n\n\n\n\n\nResults show that when people experience higher than usual in-game need frustration, they are less likely to play on the following day—but that this relationship is very small. Nonetheless, in contrast to the robust null results for game need satisfaction across various specifications, this provides some initial evidence that need frustration may be more salient for day-to-day change in gaming behavior than need satisfaction.\n\n\n7.3.10 S10: H3 displacement by specific core life domain\nThe main H3 analysis aggregated all core life domains (work/school, social engagements, sleep/eating/fitness, caretaking) into a single binary indicator. Here we test whether specific domains show differential relationships with global need satisfaction.\n\n\nShow code (S10: Prepare domain-specific displacement indicators)\n# Create domain-specific displacement indicators\ndat_domains &lt;- dat |&gt;\n  left_join(\n    activity_categories |&gt; select(pid, wave, activity_label),\n    by = c(\"pid\", \"wave\")\n  ) |&gt;\n  mutate(\n    displaced_work_school = activity_label == \"work_school\",\n    displaced_social = activity_label == \"social_engagement\",\n    displaced_health_sleep = activity_label == \"sleep_eat_fitness\",\n    displaced_caretaking = activity_label == \"caretaking\"\n  )\n\n\n\n\nShow code (S10: Fit H3 models for each core life domain)\n# File-based caching\ns10_cache_file &lt;- \"data/models/s10_fits.rds\"\ns10_pooled_file &lt;- \"data/models/s10_pooled.rds\"\n\nif (file.exists(s10_cache_file) && file.exists(s10_pooled_file)) {\n  message(\"Loading cached S10 model fits\")\n  s10_fits &lt;- readRDS(s10_cache_file)\n  s10_pooled &lt;- readRDS(s10_pooled_file)\n} else {\n  message(\"Fitting S10 models...\")\n\n  # Fit separate model for each domain\n  domains &lt;- c(\n    \"displaced_work_school\",\n    \"displaced_social\",\n    \"displaced_health_sleep\",\n    \"displaced_caretaking\"\n  )\n\n  s10_fits &lt;- list()\n  s10_pooled &lt;- list()\n\n  for (domain in domains) {\n    message(glue(\"Fitting model for {domain}\"))\n\n    # Filter to only observations where this specific domain could be displaced\n    # (i.e., where the activity_label indicates this domain or other)\n    domain_fits &lt;- lapply(1:m_imputations, function(i) {\n      dat_i &lt;- dat_domains |&gt;\n        filter(.imp == i, !is.na(!!sym(domain)))\n\n      glmmTMB(\n        as.formula(glue(\n          \"global_ns ~ {domain} + (1 + {domain} | pid) + ar1(wave + 0 | pid)\"\n        )),\n        data = dat_i\n      )\n    })\n\n    s10_fits[[domain]] &lt;- domain_fits\n    s10_pooled[[domain]] &lt;- pool(domain_fits)\n  }\n\n  # Save to cache\n  dir.create(\"data/models\", showWarnings = FALSE, recursive = TRUE)\n  saveRDS(s10_fits, s10_cache_file)\n  saveRDS(s10_pooled, s10_pooled_file)\n  message(\"S10 models saved to cache\")\n}\n\n\n\n\nShow code (Create S10 results table)\n# Extract results for each domain\ns10_results &lt;- bind_rows(\n  lapply(names(s10_pooled), function(domain) {\n    summary(s10_pooled[[domain]]) |&gt;\n      as_tibble() |&gt;\n      filter(str_detect(term, \"TRUE\")) |&gt;\n      select(term, estimate, std.error, statistic, p.value) |&gt;\n      mutate(\n        Domain = case_when(\n          domain == \"displaced_work_school\" ~ \"Work/School\",\n          domain == \"displaced_social\" ~ \"Social Engagement\",\n          domain == \"displaced_health_sleep\" ~ \"Sleep/Eating/Fitness\",\n          domain == \"displaced_caretaking\" ~ \"Caretaking\",\n          TRUE ~ domain\n        )\n      ) |&gt;\n      select(Domain, estimate, std.error, statistic, p.value)\n  })\n)\n\ns10_results |&gt;\n  mutate(\n    across(c(estimate, std.error, statistic), ~ round(.x, 3)),\n    p.value = case_when(\n      p.value &lt; 0.001 ~ \"&lt;.001\",\n      p.value &lt; 0.01 ~ sprintf(\"%.3f\", p.value),\n      TRUE ~ sprintf(\"%.2f\", p.value)\n    )\n  ) |&gt;\n  tt(\n    escape = TRUE,\n    notes = \"All models include random intercepts, random slopes, and AR(1) autocorrelation. Estimates represent the difference in global need satisfaction when the specific domain was displaced vs. not displaced.\"\n  ) |&gt;\n  style_tt(fontsize = 0.8) |&gt;\n  style_tt(i = 0, bold = TRUE)\n\n\n\n\nTable 18: H3 sensitivity analysis: Effect of displacing specific core life domains on global need satisfaction\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Domain\n                estimate\n                std.error\n                statistic\n                p.value\n              \n        \n        All models include random intercepts, random slopes, and AR(1) autocorrelation. Estimates represent the difference in global need satisfaction when the specific domain was displaced vs. not displaced.\n        \n                \n                  Work/School\n                  -0.034\n                  0.029\n                  -1.199\n                  0.23\n                \n                \n                  Social Engagement\n                  0.138\n                  0.060\n                  2.286\n                  0.02\n                \n                \n                  Sleep/Eating/Fitness\n                  -0.087\n                  0.024\n                  -3.573\n                  &lt;.001\n                \n                \n                  Caretaking\n                  0.278\n                  0.136\n                  2.048\n                  0.04\n                \n        \n      \n    \n\n\n\n\n\n\nResults showed that global need satisfaction was lower when gaming displaced work/school responsibilities and sleep/eating/fitness, but—contrary to expectations—tended to be higher when gaming displaced social engagements or caretaking. We return to this in the discussion."
  }
]